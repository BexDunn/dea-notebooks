{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate FC with field data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find field data; this field data is the Star transects from [the JRSRP geoserver wfs service](https://field-geoserver.jrsrp.com/geoserver/aus/wfs?service=wfs&version=1.1.0&request=GetFeature&typeNames=aus:star_transects&outputFormat=csv) which can be visualised through [the TERN Landscapes-JRSRP Field Data Portal](https://field.jrsrp.com/) and is available as a csv\n",
    "2. Load corresponding surface reflectance from datacube or pickle;\n",
    "3. Calculate FC and compare to field data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sensor_name\n",
    "#sensor_name = 'Landsat 8 noscaling'\n",
    "#sensor_name = 'Landsat 8 current'\n",
    "sensor_name = 'Landsat 8'\n",
    "#sensor_name = 'Landsat 7'\n",
    "#sensor_name = 'Sentinel 2A'\n",
    "#sensor_name = 'Sentinel 2B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/storage/masking.py:4: DeprecationWarning: datacube.storage.masking has moved to datacube.utils.masking\n",
      "  category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import datacube\n",
    "from fc.fractional_cover import compute_fractions\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from dea_datahandling import load_ard\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute the fractional covers as viewed by the satellite for the site\n",
    "## Required a site properties object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the fractional covers as viewed by the satellite for the site\n",
    "# Required a site properties object\n",
    "\n",
    "def fractionalCoverSatView(siteProperties):\n",
    "    '''equations to calculate fractional cover from the csv data'''\n",
    "    nTotal = siteProperties['num_points']\n",
    "    \n",
    "    # Canopy Layer\n",
    "    nCanopyBranch = siteProperties['over_b'] * nTotal / 100.0\n",
    "    nCanopyDead = siteProperties['over_d'] * nTotal / 100.0\n",
    "    nCanopyGreen = siteProperties['over_g'] * nTotal / 100.0\n",
    "    \n",
    "    # Midstory Layer\n",
    "    nMidBranch = siteProperties['mid_b'] * nTotal / 100.0\n",
    "    nMidGreen = siteProperties['mid_g'] * nTotal / 100.0\n",
    "    nMidDead = siteProperties['mid_d'] * nTotal / 100.0\n",
    "    \n",
    "    # Ground Layer\n",
    "    nGroundDeadLitter = (siteProperties['dead'] + siteProperties['litter']) * nTotal / 100.0\n",
    "    nGroundCrustDistRock = (siteProperties['crust'] + siteProperties['dist'] + siteProperties['rock']) * nTotal / 100.0\n",
    "    nGroundGreen = siteProperties['green'] * nTotal / 100.0\n",
    "    nGroundCrypto = siteProperties['crypto'] * nTotal / 100.0\n",
    "    \n",
    "    # Work out the canopy elements as viewed from above\n",
    "    canopyFoliageProjectiveCover = nCanopyGreen / (nTotal - nCanopyBranch)\n",
    "    canopyDeadProjectiveCover = nCanopyDead / (nTotal - nCanopyBranch)\n",
    "    canopyBranchProjectiveCover = nCanopyBranch / nTotal * (1.0 - canopyFoliageProjectiveCover - canopyDeadProjectiveCover)\n",
    "    canopyPlantProjectiveCover = (nCanopyGreen+nCanopyDead + nCanopyBranch) / nTotal\n",
    "    \n",
    "    # Work out the midstorey fractions\n",
    "    midFoliageProjectiveCover = nMidGreen / nTotal\n",
    "    midDeadProjectiveCover = nMidDead / nTotal\n",
    "    midBranchProjectiveCover = nMidBranch / nTotal\n",
    "    midPlantProjectiveCover = (nMidGreen + nMidDead + nMidBranch) / nTotal\n",
    "    \n",
    "    # Work out the midstorey  elements as viewed by the satellite using a gap fraction method\n",
    "    satMidFoliageProjectiveCover = midFoliageProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidDeadProjectiveCover = midDeadProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidBranchProjectiveCover = midBranchProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidPlantProjectiveCover = midPlantProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    \n",
    "    # Work out the groundcover fractions as seen by the observer\n",
    "    groundPVCover = nGroundGreen / nTotal\n",
    "    groundNPVCover = nGroundDeadLitter / nTotal\n",
    "    groundBareCover = nGroundCrustDistRock / nTotal\n",
    "    groundCryptoCover = nGroundCrypto / nTotal\n",
    "    groundTotalCover = (nGroundGreen + nGroundDeadLitter + nGroundCrustDistRock) / nTotal\n",
    "    \n",
    "    # Work out the ground cover proportions as seen by the satellite\n",
    "    satGroundPVCover = groundPVCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundNPVCover = groundNPVCover * ( 1- midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundBareCover = groundBareCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundCryptoCover = groundCryptoCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundTotalCover = groundTotalCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    \n",
    "    # Final total covers calculated using gap probabilities through all layers\n",
    "    totalPVCover = canopyFoliageProjectiveCover + satMidFoliageProjectiveCover + satGroundPVCover\n",
    "    totalNPVCover = canopyDeadProjectiveCover + canopyBranchProjectiveCover + satMidDeadProjectiveCover + satMidBranchProjectiveCover + satGroundNPVCover\n",
    "    totalBareCover = satGroundBareCover\n",
    "    totalCryptoCover = satGroundCryptoCover\n",
    "    \n",
    "    return np.array([totalPVCover,totalNPVCover+totalCryptoCover,totalBareCover])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients for FC computation\n",
    "These are the `Landsat 8 Fudge Factor` used to make the spectrally different sensor on Landsat 8 perform similarly to Landsats 5 and 7 in the Fractional Cover algorithm. These are incorporated in to the Collection 3 config as `regression_coefficients` in [C3 product definition yaml](https://github.com/opendatacube/datacube-alchemist/blob/C3_Processing/examples/c3_config_fc.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients for FC compute\n",
    "\n",
    "#these were used in collection 2 but are not correct as don't multiply by 10000/ 1e4\n",
    "ls8_coefficients_current = {'blue': [0.00041, 0.9747], 'green': [0.00289, 0.99779], 'red': [0.00274, 1.00446], \n",
    "                       'nir': [4e-05, 0.98906], 'swir1': [0.00256, 0.99467], 'swir2': [-0.00327, 1.02551]}\n",
    "\n",
    "#use these ones, they are correct (need to multiply by 10000 as the algorithm expects 0-10000 not 0-1)\n",
    "ls8_coefficients = {'blue': [0.00041*1e4, 0.9747], 'green': [0.00289*1e4, 0.99779], 'red': [0.00274*1e4, 1.00446], \n",
    "                       'nir': [4e-05*1e4, 0.98906], 'swir1': [0.00256*1e4, 0.99467], 'swir2': [-0.00327*1e4, 1.02551]}\n",
    "\n",
    "s2_coefficients = {'blue':[-0.0022*1e4, 0.9551],\n",
    "                   'green':[0.0031*1e4, 1.0582],\n",
    "                   'red':[0.0064*1e4, 0.9871],\n",
    "                   'nir':[0.012*1e4, 1.0187],\n",
    "                   'swir1':[0.0079*1e4, 0.9528],\n",
    "                   'swir2':[-0.0042*1e4, 0.9688]}\n",
    "\n",
    "# compute FC \n",
    "def compute_fc(input_ds, regression_coefficients):\n",
    "    '''takes input dataset and multiplies by regression coefficients to compute fractional cover.\n",
    "    returns an xarray DataArray with pv,npv,bs,ue bands'''\n",
    "    \n",
    "    input_data = input_ds.to_array().data\n",
    "    is_valid_array= (input_data >0).all(axis=0)\n",
    "    # Set nodata to 0                                                       \n",
    "    input_data[:, ~is_valid_array] = 0\n",
    "    # compute fractional_cover\n",
    "    output_data = compute_fractions(input_data, regression_coefficients)\n",
    "    output_data[:, ~is_valid_array] = -1\n",
    "    return xr.DataArray(output_data, dims=('band','y','x'),\n",
    "                        coords={'x':input_ds.x, 'y':input_ds.y, 'band':['pv', 'npv', 'bs', 'ue']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select good pixels using pixel quality\n",
    "def ls_good(pq):\n",
    "    return masking.make_mask(pq, cloud_acca = \"no_cloud\", cloud_fmask = \"no_cloud\",\n",
    "                             cloud_shadow_acca = \"no_cloud_shadow\",\n",
    "                             cloud_shadow_fmask = \"no_cloud_shadow\",\n",
    "                             contiguous = True)\n",
    "def s2_good(pq):\n",
    "    return pq == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the query for each sensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral bands used for fractional cover calculation\n",
    "\n",
    "#this is correct for collection3  \n",
    "ls_bands = ['nbart_green','nbart_red','nbart_nir','nbart_swir_1','nbart_swir_2']\n",
    "\n",
    "#this is correct for collection 3\n",
    "s2_bands = ['nbart_green','nbart_red','nbart_nir_1','nbart_swir_2','nbart_swir_3']\n",
    "\n",
    "# sensor specific configurations - note no Landsat 5 as doesn't overlap with site surveys\n",
    "\n",
    "sensor_config = {'Landsat 7':{'startdate':'1999-05-01', #updated for collection3\n",
    "                              'product':'ga_ls7e_ard_3', \n",
    "                              'bands':ls_bands,\n",
    "                              'resolution':(-30,30), \n",
    "                              'fc_coefficients': None}, \n",
    "                 \n",
    "                 'Landsat 8 noscaling':{'startdate':'2013-03-01',\n",
    "                                        'product':'ga_ls8c_ard_3', \n",
    "                                        'bands':ls_bands,\n",
    "                                        'resolution':(-30,30), \n",
    "                                        'fc_coefficients': None}, \n",
    "                 \n",
    "                 'Landsat 8':{'startdate':'2013-03-01', \n",
    "                              'product':'ga_ls8c_ard_3', \n",
    "                              'bands':ls_bands,\n",
    "                              'resolution':(-30,30), \n",
    "                              'fc_coefficients':ls8_coefficients}, \n",
    "                 \n",
    "                 'Landsat 8 current':{'startdate':'2013-03-01', \n",
    "                                      'product':'ga_ls8c_ard_3', \n",
    "                                      'bands':ls_bands,\n",
    "                                      'resolution':(-30,30), \n",
    "                                      'fc_coefficients':ls8_coefficients_current}, \n",
    "                 \n",
    "                 'Sentinel 2A':{'startdate':'2015-07-01', \n",
    "                                'product':'s2a_ard_granule', \n",
    "                                'bands':s2_bands,\n",
    "                                'resolution':(-10,10), \n",
    "                                'fc_coefficients':s2_coefficients},\n",
    "                 \n",
    "                'Sentinel 2B':{'startdate':'2017-06-01', \n",
    "                               'product':'s2b_ard_granule', \n",
    "                               'bands':s2_bands,\n",
    "                               'resolution':(-10,10), \n",
    "                               'fc_coefficients':s2_coefficients}\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load field data in from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load star_transects field data \n",
    "field = pd.read_csv('star_transects_28092020.csv')\n",
    "field['geometry'] = field.geom.apply(wkt.loads)\n",
    "field = gpd.GeoDataFrame(field)\n",
    "\n",
    "#field data comes in in WGS84\n",
    "field.crs = {'init': 'EPSG:4326'}\n",
    "\n",
    "#transform to Australian Albers Equal Area \n",
    "field = field.to_crs({'init':'EPSG:3577'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by date - get dates later than the first observation of the satellite\n",
    "field = field.loc[field['obs_time'] > sensor_config[sensor_name]['startdate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate field measured fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate field measured fractions\n",
    "field = field.merge(\n",
    "    field.apply(fractionalCoverSatView, axis=1, result_type= 'expand').rename(\n",
    "        columns = {0:'total_pv',1:'total_npv',2:'total_bs'}),\n",
    "    left_index=True, right_index=True)\n",
    "field = field[field.apply(lambda x: x['total_pv']+x['total_npv']+x['total_bs'], axis=1) >0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match to albers tiles to check distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points is 2602\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a05904e2cb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     , on='label', how='right')\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total number of data points is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Largest number of data points in a tile is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_tiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield_tiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \"\"\"\n\u001b[1;32m   2109\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_argmax_with_skipna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanargmax\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_arg_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "# Match to albers tiles to check distribution\n",
    "albers_tiles = gpd.read_file('Albers_Australia_Coast_and_Islands.shp')\n",
    "albers_tiles.crs = {'init':'EPSG:3577'}\n",
    "matched = gpd.sjoin(field, albers_tiles, how='inner', op = 'intersects')\n",
    "field_tiles = albers_tiles.merge(matched.groupby('label')['FID'].count().sort_values(ascending=False).to_frame('count').reset_index()\n",
    "    , on='label', how='right')\n",
    "print(\"Total number of data points is\",len(field))\n",
    "print(\"Largest number of data points in a tile is\", field_tiles.loc[field_tiles['count'].idxmax()]['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual check of field data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check of field data distribution\n",
    "f, axes = plt.subplots(1, 2, figsize=(14,7))\n",
    "plt.suptitle('Density of field data (star transects per albers tile)', size =14)\n",
    "ax0 = field.plot(markersize=1, ax=axes[0])\n",
    "albers_tiles.plot(alpha=0.2, ax = ax0)\n",
    "\n",
    "ax1 =field_tiles.plot(column='count', cmap = 'viridis', ax=axes[1])\n",
    "albers_tiles.plot(alpha=0.2, ax = ax1)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from cube\n",
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find temporally and spatially aligned EO data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test data\n",
    "# row = field.iloc[-1]\n",
    "# sensor_name = 'Landsat 8'\n",
    "# plot_rad = 50\n",
    "# window_days = 60 #window_days = 15\n",
    "# #sensor_config = sensor_config[sensor_name]\n",
    "# sensor_config =sensor_config['Landsat 8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nTotal = siteProperties['num_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate fractional cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractional cover\n",
    "def fractionalCover(row, sensor_config = sensor_config[sensor_name], plot_rad = 50, window_days = 15):\n",
    "    '''this finds data within 15 days of an observation and 50 ??? of an observation\n",
    "    #FIXME check nodata defaults here to -1, I think we need to replace with 255 '''\n",
    "\n",
    "    # nodata default to return in case no data matches the chosen window around the field observation\n",
    "    fc_dict = {'fc_time': '', 'pv': -1, 'npv': -1, 'bs': -1, 'pv_std': -1, 'npv_std': -1, 'bs_std': -1 }\n",
    "\n",
    "    # define search - grab near observations in space and time\n",
    "    x = row.geometry.x - plot_rad, row.geometry.x + plot_rad\n",
    "    y = row.geometry.y - plot_rad, row.geometry.y + plot_rad\n",
    "    time = (str(np.datetime64(row.obs_time) - np.timedelta64(window_days,'D')),\n",
    "            str(np.datetime64(row.obs_time) + np.timedelta64(window_days,'D'))\n",
    "           )\n",
    "\n",
    "    #use a reusable query dictionary\n",
    "    query = {'measurements':sensor_config['bands'],\n",
    "             'group_by':'solar_day',\n",
    "             'x' : x, \n",
    "             'y' : y,  \n",
    "             'time' : time, \n",
    "             'crs' : 'EPSG:3577', #this defines the crs of the input query\n",
    "             'resolution' : sensor_config['resolution'],\n",
    "             'output_crs' : 'EPSG:3577'}          \n",
    "\n",
    "    try: \n",
    "        #need to test if load_ard will return data here, as the alternative is that the data is not returned\n",
    "        nbart = load_ard(dc,\n",
    "            products = [sensor_config['product']], #need square brackets to deliver as a list\n",
    "            min_gooddata=1, #need all valid pixels for the comparison\n",
    "            fmask_categories=['valid'], #don't want snow or water in fractional cover comparison\n",
    "            mask_pixel_quality=True, #this could give us some issues with dtype later on\n",
    "            mask_contiguity='nbart_contiguity',\n",
    "            ls7_slc_off=True,\n",
    "            **query); #suppress output for this function to save printing space\n",
    "        \n",
    "    except ValueError:\n",
    "        print(f\"No data found at {x},{y},{time}\")\n",
    "        return fc_dict\n",
    "    \n",
    "    # If there aren't any results, this function will return nodata values.\n",
    "    if len(nbart.time) == 0: return fc_dict\n",
    "\n",
    "    ### choose the closest clear timestep to keep\n",
    "\n",
    "    # only keep closest time\n",
    "    nbart = nbart.isel(time=[np.abs(nbart.time-np.datetime64(row.obs_time)).argmin()])\n",
    "\n",
    "    # compute FC\n",
    "    fc = nbart.groupby('time').apply(compute_fc,\n",
    "                                     regression_coefficients = sensor_config['fc_coefficients'],\n",
    "                                    ).to_dataset(dim='band')\n",
    "\n",
    "    ## Not sure why groupby was needed here?\n",
    "    #fc_mean = fc.where(fc>=0).groupby('time').mean()\n",
    "    # fc_std = fc.where(fc>=0).groupby('time').std()\n",
    "        # take average\n",
    "    fc_mean = fc.where(fc>=0).groupby('time').mean(dim=['x','y'])\n",
    "    fc_std = fc.where(fc>=0).groupby('time').std(dim=['x','y'])\n",
    "\n",
    "    fc_dict['fc_time'] = fc.time.values[0].astype(str)\n",
    "    for var_name in fc_mean.data_vars:\n",
    "        fc_dict[var_name.lower()] = fc_mean[var_name].values[0]\n",
    "        fc_dict[var_name.lower()+'_std'] = fc_std[var_name].values[0]\n",
    "        \n",
    "    return fc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Fractional Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# If there aren't any results, this function will return nodata values.\n",
    "fractions = field.apply(fractionalCover, axis=1, result_type = 'expand')\n",
    "field = field.merge(fractions, how = 'inner', left_index=True, right_index=True)\n",
    "field = field[field['pv']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.to_file('C3_newdata_field_with_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = gpd.read_file('C3_newdata_field_with_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "def validate(field_all, title=None):\n",
    "    field = field_all[(field_all[['pv','npv','bs']]>=0.).all(axis=1)]\n",
    "    field = field[(field[['pv_std','npv_std','bs_std']]<=10.).all(axis=1)]\n",
    "    field = field[field['ue'] <25]\n",
    "    print(\"# of validation points:\", len(field))\n",
    "    \n",
    "    regr = linear_model.LinearRegression(fit_intercept=False)    \n",
    "\n",
    "    f = plt.figure(figsize=(12,12))\n",
    "    gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "    xedges=yedges=list(np.arange(0,102,2))\n",
    "    X, Y = np.meshgrid(xedges, yedges)\n",
    "    cmname='YlGnBu'\n",
    "    if title: plt.suptitle(title)\n",
    "    \n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    field.plot(markersize=1, ax= ax1, color='r')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_title('Field Sites')\n",
    "    ax1.text(0.05, 0.05, \"%d points\"%len(field), transform=ax1.transAxes)\n",
    "    \n",
    "    rmses = []\n",
    "    for band_id, band in enumerate(['BS','PV','NPV']):\n",
    "        arr1 = field['total_%s'%band.lower()].values.ravel()*100.\n",
    "        arr2 = field[band.lower()].values.ravel()\n",
    "        regr.fit(arr1[:,np.newaxis], arr2[:,np.newaxis])\n",
    "        \n",
    "        print('Band:{0}, slope={1}, r2={2}'.format(band, regr.coef_[0][0],\n",
    "                                                regr.score(arr1[:,np.newaxis], arr2[:,np.newaxis])))\n",
    "        sr = spearmanr(arr1, arr2)[0]\n",
    "        print('Correlations:', pearsonr(arr1, arr2)[0], sr, kendalltau(arr1, arr2)[0])\n",
    "        rmse = np.sqrt(mean_squared_error(arr1, arr2))\n",
    "        print('RMSE:',rmse)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "        ax1 = plt.subplot(gs[band_id+1])\n",
    "        ax1.scatter(arr1, arr2, s=3)\n",
    "        ax1.set_title(band)\n",
    "        \n",
    "        ax1.plot([0,100],[0,100])\n",
    "        ax1.plot(np.arange(0,100,10), regr.predict(np.arange(0,100,10)[:,np.newaxis]), ':')\n",
    "        ax1.text(5, 95, 'spearmanr = {0:.2f}'.format(sr))\n",
    "        ax1.text(5, 90, 'rmse = {0:.2f}'.format(rmse))\n",
    "        ax1.set_xlabel('Field Measured')\n",
    "        ax1.set_ylabel('%s FC'%sensor_name.upper())\n",
    "        ax1.set_xlim((0,100))\n",
    "        ax1.set_ylim((0,100))\n",
    "    \n",
    "    f.savefig('c3_newdata_validate_fc_%s.png'%''.join(sensor_name.split()))\n",
    "\n",
    "\n",
    "validate(field, title=sensor_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
