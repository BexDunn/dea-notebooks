{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasselled Cap Wetness Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Background:__\n",
    "\n",
    "__Before you run this notebook:__ This notebook uses the dea module. You need to run \"module load dea\" in a terminal window and then launch jupyter notebooks in the same window so that your notebook can 'see' the module.\n",
    "\n",
    "__What does this notebook do?__\n",
    "\n",
    "__Date:__ May 2018\n",
    "\n",
    "__Authors:__ Bex Dunn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__You will need:__\n",
    "- to update the output location for the save files to somewhere you have permissions to access\n",
    "- a shapefile of the area of interest (if this is too big you will run into MemoryErrors)\n",
    "\n",
    "\n",
    "#### Things to improve:\n",
    "- TCI coeffs in process of investigation/confirmation -check with author before interpreting.\n",
    "- Write start and end of epoch dates to outfile description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules from standard libraries, datacube and files\n",
    "Select 'Trust this notebook' to import these modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:44.388273Z",
     "start_time": "2018-05-25T03:38:40.234519Z"
    }
   },
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "import os\n",
    "\n",
    "\n",
    "#get some libraries\n",
    "\n",
    "#modules for datacube\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.storage import masking\n",
    "\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import shape\n",
    "import numpy as np #need this for pq fuser\n",
    "\n",
    "#libraries for polygon and polygon mask\n",
    "import fiona\n",
    "import shapely.geometry\n",
    "import rasterio.features\n",
    "import rasterio\n",
    "from datacube.utils import geometry\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage.masking import mask_invalid_data\n",
    "\n",
    "#for writing to netcdf\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "#dealing with system commands\n",
    "import sys\n",
    "\n",
    "\n",
    "#####These not needed for raijin::::\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#suppress warnings thrown when using inequalities in numpy (the threshold values!)\n",
    "import warnings\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the functions we need to load and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:44.405537Z",
     "start_time": "2018-05-25T03:38:44.391285Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_nbart(sensor,query,bands_of_interest): \n",
    "    '''loads nbart data for a sensor, masks using pq, then filters out terrain -999s\n",
    "    function written 23-08-2017 based on dc v1.5.1'''  \n",
    "    dataset = []\n",
    "    product_name = '{}_{}_albers'.format(sensor, 'nbart')\n",
    "    print('loading {}'.format(product_name))\n",
    "    ds = dc.load(product=product_name, measurements=bands_of_interest,\n",
    "                 group_by='solar_day', **query)\n",
    "    #grab crs defs from loaded ds if ds exists\n",
    "    if ds:\n",
    "        crs = ds.crs\n",
    "        affine = ds.affine\n",
    "        print('loaded {}'.format(product_name))\n",
    "        mask_product = '{}_{}_albers'.format(sensor, 'pq')\n",
    "        sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser,\n",
    "                            group_by='solar_day', **query)\n",
    "        if sensor_pq:\n",
    "            print('making mask {}'.format(mask_product))\n",
    "            cloud_free = masking.make_mask(sensor_pq.pixelquality,\n",
    "                                           cloud_acca='no_cloud',\n",
    "                                           cloud_shadow_acca = 'no_cloud_shadow',                           \n",
    "                                           cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                                           cloud_fmask='no_cloud',\n",
    "                                           blue_saturated = False,\n",
    "                                           green_saturated = False,\n",
    "                                           red_saturated = False,\n",
    "                                           nir_saturated = False,\n",
    "                                           swir1_saturated = False,\n",
    "                                           swir2_saturated = False,\n",
    "                                           contiguous=True)\n",
    "            ds = ds.where(cloud_free)\n",
    "            ds.attrs['crs'] = crs\n",
    "            ds.attrs['affine'] = affine\n",
    "            print('masked {} with {} and filtered terrain'.format(product_name,mask_product))\n",
    "            # nbarT is correctly used to correct terrain by replacing -999.0 with nan\n",
    "            ds=ds.where(ds!=-999.0)\n",
    "        else: \n",
    "            print('did not mask {} with {}'.format(product_name,mask_product))\n",
    "    else:\n",
    "        print ('did not load {}'.format(product_name)) \n",
    "\n",
    "    if len(ds)>0:\n",
    "        return ds\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define some functions to calculate the wetness and the wetness summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:44.415200Z",
     "start_time": "2018-05-25T03:38:44.407767Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_wetness(sensor_data,sensor):\n",
    "    '''This function multiplies band data by wetness coefficients to produce a \"wetness\" band.\n",
    "    sensor_data is surface reflectance data loaded from the datacube\n",
    "    sensor = 'ls5, 'ls7' or 'ls8'\n",
    "    Coefficients are from Crist and Cicone 1984 for ls5 and ls7, and from Baig, Zhang, Shuai & Tong for ls8\n",
    "    function written 23-08-2017 based on dc v1.5.1'''\n",
    "    \n",
    "    wetness_coeff ={'ls5':{'blue':0.151, 'green':0.179, 'red':0.330, 'nir':0.341, 'swir1':-0.711, 'swir2':-0.457},\n",
    "                    'ls7':{'blue':0.151, 'green':0.179, 'red':0.330, 'nir':0.341, 'swir1':-0.711, 'swir2':-0.457},\n",
    "                    'ls8':{'blue':0.1511,'green':0.1973,'red':0.3283,'nir':0.3407,'swir1':-0.7117,'swir2':-0.4559}}  \n",
    "    \n",
    "    #if there is sensor data for the time period\n",
    "    if sensor_data is not None: \n",
    "        #make a deep copy of the sensor data\n",
    "        wetness = sensor_data.copy(deep=True)\n",
    "        #iterate over the spectral bands\n",
    "        for band_name in sensor_data.data_vars:\n",
    "            #multiply each band by the wetness transform coefficient to get a band-specific wetness value\n",
    "            wetness_band = sensor_data[band_name]*wetness_coeff[sensor][band_name]\n",
    "            #update the existing band data with the wetness data\n",
    "            wetness.update({band_name:(['time','y','x'],wetness_band)})\n",
    "        #finally, add a wetness data variable to the array that is the sum of the wetness \"bands\"    \n",
    "        wetness['wetness']=wetness.blue+wetness.green+wetness.red+wetness.nir+wetness.swir1+wetness.swir2    \n",
    "        print('calculated wetness for {}'.format(sensor))\n",
    "        wetness = wetness.drop(('blue','green','red','nir','swir1','swir2'))\n",
    "        return wetness\n",
    "    \n",
    "    else:\n",
    "        print('did not calculate wetness for {}'.format(sensor))\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:44.423553Z",
     "start_time": "2018-05-25T03:38:44.417482Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_wetveg_overthresh(wetness,threshold=-400):\n",
    "    '''Calculate the wetness values where wetness>threshold. Inputs are wetness array and threshold value, \n",
    "    default threshold is -400. Band for wetness>threshold is added to wetness. This is not the count.'''\n",
    "    if wetness is not None:\n",
    "        with warnings.catch_warnings():\n",
    "            #suppress irritating behaviour in xarray.where\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            #water_plus_wetveg is wetness values where wetness>threshold\n",
    "            wetness['water_plus_wetveg'] = wetness.wetness.where(wetness.wetness>threshold)\n",
    "            print('thresholded wetness added to array')\n",
    "            return wetness\n",
    "    else:\n",
    "        print('did not calculate wetness overthreshold' )\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:44.432191Z",
     "start_time": "2018-05-25T03:38:44.425804Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_wets(wetness):\n",
    "    '''count the number of wetness scenes for each pixel,\n",
    "    count the amount of times that water plus wet veg is above the threshold\n",
    "    load both into memory (this assumes you are using dask),\n",
    "    return a dictionary of wet count and threshold count'''\n",
    "    if wetness is not None:\n",
    "        #count the number of wetness scenes for each pixel\n",
    "        wet_count = wetness.wetness.count(dim='time')\n",
    "\n",
    "        #count the amount of times that water plus wet veg is above the threshold\n",
    "        threshold_count= wetness.water_plus_wetveg.count(dim='time')\n",
    "        \n",
    "        #bring both counts into memory\n",
    "        wet_count.load()\n",
    "        threshold_count.load()\n",
    "        \n",
    "        #define dictionary of wet count and threshold count\n",
    "        counts = {'wet count':wet_count, 'threshold count':threshold_count}\n",
    "        print('counted')\n",
    "        return counts\n",
    "    else:\n",
    "        print('did not count' )\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function to write out to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:45.057130Z",
     "start_time": "2018-05-25T03:38:45.052234Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_your_netcdf(data, dataset_name, filename,crs):\n",
    "    '''this function turns an xarray dataarray into a dataset so we can write it to netcdf. It adds on a crs definition\n",
    "    from the original array. data = your xarray dataset, dataset_name is a string describing your variable'''    \n",
    "    #turn array into dataset so we can write the netcdf\n",
    "    dataset= data.to_dataset(name=dataset_name)\n",
    "    #grab our crs attributes to write a spatially-referenced netcdf\n",
    "    dataset.attrs['crs'] = crs\n",
    "    #dataset.dataset_name.attrs['crs'] = crs\n",
    "    try:\n",
    "        write_dataset_to_netcdf(dataset, filename)\n",
    "    except RuntimeError as err:\n",
    "        print(\"RuntimeError: {0}\".format(err))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mainline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the save location for netcdf outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:46.478128Z",
     "start_time": "2018-05-25T03:38:46.473252Z"
    }
   },
   "outputs": [],
   "source": [
    "#save netcdf outputs to this folder:\n",
    "#netcdf_output_loc ='/g/data/r78/rjd547/groundwater_activities/Analysis/'\n",
    "netcdf_output_loc ='/g/data/r78/rjd547/groundwater_activities/Analysis/TCW_stats/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the location of the (small) shapefile to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:47.201956Z",
     "start_time": "2018-05-25T03:38:47.137182Z"
    }
   },
   "outputs": [],
   "source": [
    "#code to work with a polygon input\n",
    "shape_file = ('/g/data/r78/rjd547/groundwater_activities/Analysis/slice.shp')\n",
    "# open all the shapes within the shape file\n",
    "shapes = fiona.open(shape_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose which polygon in the shapefile to use (if there are more than one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:48.166061Z",
     "start_time": "2018-05-25T03:38:48.161141Z"
    }
   },
   "outputs": [],
   "source": [
    "#i is the index of the polygon in the shape file we have chosen - change i to choose a different polygon\n",
    "i =0 \n",
    "print('polygon index is '+str(i))\n",
    "if i > len(shapes):\n",
    "    print('index not in the range for the shapefile'+str(i)+' not in '+str(len(shapes)))\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the coordinate reference system from the shapefile, and get the name of the shape from the shapefile too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:49.196798Z",
     "start_time": "2018-05-25T03:38:49.163888Z"
    }
   },
   "outputs": [],
   "source": [
    "#copy attributes from shapefile and define shape_name\n",
    "geom_crs = geometry.CRS(shapes.crs_wkt)\n",
    "geo = shapes[i]['geometry']\n",
    "geom = geometry.Geometry(geo, crs=geom_crs)\n",
    "geom_bs = shapely.geometry.shape(shapes[i]['geometry'])\n",
    "shape_name = shape_file.split('/')[-1].split('.')[0]+'_'+str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### give the file a name and check if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:50.028227Z",
     "start_time": "2018-05-25T03:38:50.022722Z"
    }
   },
   "outputs": [],
   "source": [
    "# #check if the file has already been written:\n",
    "filename = netcdf_output_loc+shape_name+'.nc'\n",
    "if os.path.isfile(filename):\n",
    "    print('{} already exists'.format(filename))\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:51.094694Z",
     "start_time": "2018-05-25T03:38:50.395561Z"
    }
   },
   "outputs": [],
   "source": [
    "#tell the datacube which app to use\n",
    "dc = datacube.Datacube(app='dc-nbar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose the time epoch to query the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:51.118014Z",
     "start_time": "2018-05-25T03:38:51.114576Z"
    }
   },
   "outputs": [],
   "source": [
    "#### DEFINE SPATIOTEMPORAL RANGE AND BANDS OF INTEREST\n",
    "#Define temporal range\n",
    "start_of_epoch = '2017-01-01'\n",
    "#start_of_epoch = '2016-01-01'\n",
    "#need a variable here that defines a rolling 'latest observation'\n",
    "end_of_epoch =  '2017-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose the spectral bands of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:51.956657Z",
     "start_time": "2018-05-25T03:38:51.952564Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "bands_of_interest = ['blue',\n",
    "                     'green',\n",
    "                     'red',\n",
    "                     'nir',\n",
    "                     'swir1',\n",
    "                     'swir2'\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up the query that the datacube will read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:38:52.772604Z",
     "start_time": "2018-05-25T03:38:52.769163Z"
    }
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "    'time': (start_of_epoch, end_of_epoch), 'geopolygon': geom\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in the nbart data for each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.302951Z",
     "start_time": "2018-05-25T03:38:53.618624Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is done separately instead of in a loop because the datasets can be quite large.\n",
    "#currently this is a way of memory handling -there is probably a better way of doing it.\n",
    "sensor1_nbart=load_nbart('ls5',query,bands_of_interest)\n",
    "sensor2_nbart=load_nbart('ls7',query,bands_of_interest)\n",
    "sensor3_nbart=load_nbart('ls8',query,bands_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate wetness for each timeslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.483696Z",
     "start_time": "2018-05-25T03:39:28.305257Z"
    }
   },
   "outputs": [],
   "source": [
    "wetness_sensor1_nbart=calc_wetness(sensor1_nbart,'ls5')\n",
    "wetness_sensor2_nbart=calc_wetness(sensor2_nbart,'ls7')\n",
    "wetness_sensor3_nbart=calc_wetness(sensor3_nbart,'ls8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate wetness over the threshold for each timeslice (remove values under the threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.515047Z",
     "start_time": "2018-05-25T03:39:28.488062Z"
    }
   },
   "outputs": [],
   "source": [
    "water_plus_wetveg_1 =calc_wetveg_overthresh(wetness_sensor1_nbart)\n",
    "water_plus_wetveg_2 =calc_wetveg_overthresh(wetness_sensor2_nbart)\n",
    "water_plus_wetveg_3 =calc_wetveg_overthresh(wetness_sensor3_nbart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count number of wetness scenes and number of times tcw above threshold for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.545951Z",
     "start_time": "2018-05-25T03:39:28.517343Z"
    }
   },
   "outputs": [],
   "source": [
    "counts_sensor_1_nbart = count_wets(wetness_sensor1_nbart)\n",
    "counts_sensor_2_nbart = count_wets(wetness_sensor2_nbart)\n",
    "counts_sensor_3_nbart = count_wets(wetness_sensor3_nbart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide the number of times wetness is seen per pixel by the number of wetness scenes per pixel to get a proportion of time that the pixel is wet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.559310Z",
     "start_time": "2018-05-25T03:39:28.548231Z"
    }
   },
   "outputs": [],
   "source": [
    "counts_list = [counts_sensor_1_nbart, counts_sensor_2_nbart,counts_sensor_3_nbart]\n",
    "threshold_list =[]\n",
    "wet_list=[]\n",
    "for acount in counts_list:\n",
    "    #test for data existence\n",
    "    if acount is not None:\n",
    "        wet_count = acount['wet count']\n",
    "        threshold = acount['threshold count']\n",
    "        threshold_list.append(threshold)\n",
    "        wet_list.append(wet_count)\n",
    "#times wetness is over threshold by pixel         \n",
    "threshold_allsensors = sum(threshold_list) \n",
    "#number of wetness scenes by pixel\n",
    "wet_count_allsensors = sum(wet_list)        \n",
    "wet_proportion_allsensors = threshold_allsensors/wet_count_allsensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the tasselled cap wetness summary for your polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.979379Z",
     "start_time": "2018-05-25T03:39:28.561639Z"
    }
   },
   "outputs": [],
   "source": [
    "wet_proportion_allsensors.plot(cmap ='gist_earth_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.985728Z",
     "start_time": "2018-05-25T03:39:28.981243Z"
    }
   },
   "outputs": [],
   "source": [
    "print('successfully ran TCW for '+shape_name+' polygon number '+str(i))\n",
    "eprint('successfully ran TCW for '+shape_name+' polygon number '+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get the crs for the netcdf from whichever wetness array actually has one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:28.992735Z",
     "start_time": "2018-05-25T03:39:28.987650Z"
    }
   },
   "outputs": [],
   "source": [
    "if wetness_sensor1_nbart is not None:\n",
    "    crs = wetness_sensor1_nbart.crs\n",
    "else:\n",
    "    if wetness_sensor2_nbart is not None:\n",
    "        crs = wetness_sensor2_nbart.crs\n",
    "    else: \n",
    "        crs = wetness_sensor3_nbart.crs\n",
    "print(crs)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:29.033667Z",
     "start_time": "2018-05-25T03:39:28.994851Z"
    }
   },
   "outputs": [],
   "source": [
    "write_your_netcdf(wet_proportion_allsensors,'tcw',filename=filename, crs=crs)\n",
    "print('successfully wrote tcw netcdf for '+shape_name+' polygon number '+str(i))\n",
    "eprint('successfully wrote tcw netcdf for for '+shape_name+' polygon number '+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:39:29.072211Z",
     "start_time": "2018-05-25T03:39:29.035512Z"
    }
   },
   "outputs": [],
   "source": [
    "#clear_observations is count of wetness scenes at pixel\n",
    "write_your_netcdf(wet_count_allsensors,'clearobs',filename=netcdf_output_loc+shape_name+'_clearobs.nc',crs=crs)\n",
    "print('successfully wrote clearobs netCDF for '+shape_name+' polygon number '+str(i))\n",
    "eprint('successfully wrote clearobs netCDFfor '+shape_name+' polygon number '+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the two cells above were successful you now have netcdfs of tasselled cap wetness and a the clear observations for your location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
