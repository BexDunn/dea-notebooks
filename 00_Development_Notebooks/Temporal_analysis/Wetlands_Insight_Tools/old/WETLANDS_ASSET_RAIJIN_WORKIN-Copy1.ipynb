{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T22:48:07.501507Z",
     "start_time": "2019-02-19T22:48:07.425278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape file is /g/data/r78/rjd547/Ramsar_Wetlands/ExplodedRAMSAR.shp\n",
      "system argument received is 1\n",
      "chunk size is 9\n",
      "There are 30 generated chunks\n",
      "Running for polygon IDs in the range 0 to 9\n"
     ]
    }
   ],
   "source": [
    "# #!/usr/bin/python\n",
    "\n",
    "\n",
    "# | Authors:  | Bex Dunn|\n",
    "# |----------|----------------|\n",
    "# | Created: | Jan 7, 2019 |\n",
    "# | Last edited: | Jan 22,2019 |\n",
    "\n",
    "\n",
    "#  Before running this script load these modules:\n",
    "# `module use /g/data/v10/public/modules/modulefiles` \n",
    "# `module load dea`\n",
    "# This code is designed to run on raijin, on the Australian NCI. \n",
    "# The shell script to run this code has a *.sh extension\n",
    "\n",
    "\n",
    "# If you find an error in this code, please raise an issue at https://github.com/GeoscienceAustralia/dea-notebooks\n",
    "# \n",
    "# This code takes a supplied shapefile of a polygon and queries Digital Earth\n",
    "# Australia http://geoscienceaustralia.github.io/digitalearthau/\n",
    "# for WOfS, Fractional Cover and NBART. It calculates thresholded tasselled cap wetness. The dominant result for\n",
    "# each pixel is calculated and the percentage area of the polygon covered by water, wet vegetation, \n",
    "# photosynthetic vegetation, non-photosynthetic vegetation and bare soil is output into a jpg stacked plot and to\n",
    "# csv. The resulting data can be used to monitor changes in wetland behaviour spatiotemporally. \n",
    "\n",
    "# - Input Datasets:\n",
    "# - Landsat 5\n",
    "# - Landsat 7\n",
    "# - Landsat 8\n",
    "\n",
    "# -- Fractional Cover --\n",
    "# - PV - Photosythetic vegetation\n",
    "# - NPV - Non-Photosythetic vegetation\n",
    "# - BS - Bare Soil\n",
    "\n",
    "# - WOfS Feature Layers (WOFLs)\n",
    "\n",
    "# __Future Work:__ \n",
    "# - do this by max extent of wetness\n",
    "# - add rainfall for context -- waiting on an update as to availability of data        \n",
    "\n",
    "### Import Statements: import the modules we need ------------------------------\n",
    "\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "\n",
    "#$#$#$#$#$\n",
    "\n",
    "import datacube\n",
    "import datetime\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "from shapely import geometry\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "#keep the plotting modules in here as we want to output the stackplots to *.jpg\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "#append path to dea notebooks scripts to the system so we can access it\n",
    "sys.path.append('/g/data/r78/rjd547/jupyter_notebooks/dea-notebooks/10_Scripts')\n",
    "import DEADataHandling, DEAPlotting, TasseledCapTools\n",
    "\n",
    "# setup the datacube \n",
    "dc = datacube.Datacube(app='asset drill')\n",
    "\n",
    "### Set up polygon\n",
    "poly_path='/g/data/r78/rjd547/Ramsar_Wetlands/ExplodedRAMSAR.shp'\n",
    "print(f'Shape file is {poly_path}')\n",
    "\n",
    "#part = sys.argv[1] ###FIXME: update before running on raijin\n",
    "part = 1\n",
    "part = int(part)\n",
    "print(f'system argument received is {part}')\n",
    "\n",
    "global Output_dir\n",
    "Output_dir = '/g/data/r78/rjd547/Ramsar_Wetlands/Ramsar_Outputs_1/'\n",
    "\n",
    "# add in a delay between dc.load calls to avoid overloading the database - 5 seconds in this case\n",
    "time.sleep(5*part)\n",
    "#open the polygon\n",
    "\n",
    "#this code tells us which polygon ids will be running on this particular (node?). Shapessubset will be the subset of polygons that our function\n",
    "#will run over. ###FIXME - can we send this to some kind of multiprocessing?\n",
    "with fiona.open(poly_path) as allshapes:\n",
    "        #get the crs of the polygon file to use when processing each polygon\n",
    "        crs = geometry.CRS(allshapes.crs_wkt)\n",
    "        #get the list of all the shapes in the shapefile\n",
    "        ShapesList = list(allshapes)\n",
    "        #Desired number of chunks\n",
    "        #Set this to 32 because we have 32 CPUs that we'd like to run across\n",
    "        DesiredChunks = 32\n",
    "        ChunkSize = ceil(len(ShapesList)/DesiredChunks) #this was set due to Claire having 64000 polygons in her code\n",
    "        print(f'chunk size is {ChunkSize}')\n",
    "        print(f'There are {int(len(ShapesList)/ChunkSize)} generated chunks')\n",
    "        shapessubset = allshapes[(part - 1) * ChunkSize: part * ChunkSize]\n",
    "        print(f'Running for polygon IDs in the range {(part - 1) * ChunkSize} to {part * ChunkSize}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions that are run in the mainline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RAMSAR_polyName(shapefile):\n",
    "    ''' function designed specifically for the RAMSAR wetlands australia shapefile. Takes the shapefile and extracts\n",
    "    the ramsar name, wetland name and objectID from the ESRI shapefile format and turns it into a useful string for our output.\n",
    "    :Inputs: shapefile with RAMSAR_NAM, WETLAND_NA, and OBJECTID as properties. \n",
    "    Author: Bex Dunn Last Edited: March 2019'''\n",
    "    # get the ramsar name from the shapes \n",
    "    RAMSAR_NAME = '_'.join(shapefile['properties']['RAMSAR_NAM'].split(' '))\n",
    "    WETLAND_NAME = '_'.join(shapefile['properties']['WETLAND_NA'].split(' '))\n",
    "    STATE = '_'.join(shapefile['properties']['STATE'].split(' ')) \n",
    "    ID = shapefile['id']\n",
    "    polyName = f'{RAMSAR_NAME}-{WETLAND_NAME}-{STATE}-{ID}'\n",
    "    print(f'processing polygon {polyName}')\n",
    "    return(polyName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BigFunkyFunction(lilshape):\n",
    "    '''This is a function that does lots of things. It takes a single polygon and  '''\n",
    "    ### This is set up to be shapefile-specific. I'm not sure this can be avoided, as often shapefiles are pretty specific..\n",
    "    first_geometry = lilshape['geometry']\n",
    "    polyName = get_RAMSAR_polyName(lilshape)\n",
    "    geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "    query = {'geopolygon': geom}# this should run for all time, if there is no time set?\n",
    "    print(polyName,query)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "testin = gpd.read_file(poly_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-0\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-1\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-2\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-3\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-4\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-5\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-6\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-7\n",
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-8\n"
     ]
    }
   ],
   "source": [
    "for shape in shapessubset:\n",
    "    first_geometry = shape['geometry']\n",
    "    polyName = get_RAMSAR_polyName(shape)\n",
    "    geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "    query = {'geopolygon': geom}# this should run for all time, if there is no time set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-71-9db0d39f7a18>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-71-9db0d39f7a18>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_masked_ls578_data(landsat_masked_prop = 0.90, query, geom):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def get_masked_ls578_data(landsat_masked_prop = 0.90, query, geom):\n",
    "    '''create a function that takes in the masked proportion, query and geometry and returns the fully masked surface reflectance data'''\n",
    "    ## Set up datasets\n",
    "    #set cloudmasking threshold and load landsat nbart data\n",
    "    landsat_masked_prop = 0.90\n",
    "    ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart',\n",
    "            masked_prop=landsat_masked_prop)\n",
    "\n",
    "    ### mask the data with our original polygon to remove extra data \n",
    "\n",
    "    data = ls578_ds\n",
    "    mask = rasterio.features.geometry_mask([geom.to_crs(data.geobox.crs)for geoms in [geom]],\n",
    "                                               out_shape=data.geobox.shape,\n",
    "                                               transform=data.geobox.affine,\n",
    "                                               all_touched=False,\n",
    "                                               invert=False)\n",
    "\n",
    "    #for some reason xarray is not playing nicely with our old masking function\n",
    "    mask_xr = xr.DataArray(mask, dims = ('y','x'))\n",
    "    ls578_ds = data.where(mask_xr==False)\n",
    "    return ls578_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BigFunkyFunction(lilshape,crs):\n",
    "    '''This is a function that does lots of things. It takes a single polygon and  '''\n",
    "    ### This is set up to be shapefile-specific. I'm not sure this can be avoided, as often shapefiles are pretty specific..\n",
    "    first_geometry = lilshape['geometry']\n",
    "    polyName = get_RAMSAR_polyName(lilshape)\n",
    "    geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "    query = {'geopolygon': geom}# this should run for all time, if there is no time set?\n",
    "    \n",
    "    ## Set up datasets\n",
    "    #set cloudmasking threshold and load landsat nbart data\n",
    "    landsat_masked_prop = 0.90\n",
    "    ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart',\n",
    "            masked_prop=landsat_masked_prop)\n",
    "\n",
    "    ### mask the data with our original polygon to remove extra data \n",
    "\n",
    "    data = ls578_ds\n",
    "    mask = rasterio.features.geometry_mask([geom.to_crs(data.geobox.crs)for geoms in [geom]],\n",
    "                                               out_shape=data.geobox.shape,\n",
    "                                               transform=data.geobox.affine,\n",
    "                                               all_touched=False,\n",
    "                                               invert=False)\n",
    "\n",
    "    #for some reason xarray is not playing nicely with our old masking function\n",
    "    mask_xr = xr.DataArray(mask, dims = ('y','x'))\n",
    "    ls578_ds = data.where(mask_xr==False)\n",
    "\n",
    "    #transform the nbart into tci\n",
    "    tci = TasseledCapTools.thresholded_tasseled_cap(ls578_ds,wetness_threshold=-350, drop=True , drop_tc_bands=True)\n",
    "\n",
    "    ### create a masked version of the extent of overthreshold wetness\n",
    "\n",
    "    #select only finite values (over threshold values)\n",
    "    tcw = xr.ufuncs.isfinite(tci.wetness_thresholded)\n",
    "\n",
    "    # #reapply the polygon mask\n",
    "    tcw = tcw.where(mask_xr==False)\n",
    "\n",
    "    ### load wofls and select only wet pixels\n",
    "\n",
    "    #load wofs\n",
    "    wofls = dc.load(product = 'wofs_albers', like=ls578_ds)\n",
    "\n",
    "    #only get wet obs\n",
    "    wetwofl = masking.make_mask(wofls, wet=True)\n",
    "\n",
    "    #match the wofs observations to the nbart\n",
    "    wetwofl=wetwofl.where(wofls.time==ls578_ds.time)\n",
    "\n",
    "    ### mask the wofs obs\n",
    "\n",
    "    #mask the wofs obs with the polygon mask\n",
    "    wetwofl = wetwofl.where(mask_xr==False)\n",
    "\n",
    "    ### load in fractional cover data\n",
    "\n",
    "    #load the data according to our query\n",
    "    #choose a mask proportion to look for a clear timestep\n",
    "    fc_ds = DEADataHandling.load_clearlandsat(dc, query,product='fc',masked_prop=0.90)\n",
    "\n",
    "    ### mask FC with polygon\n",
    "\n",
    "    fc_ds = fc_ds.where(mask_xr==False)\n",
    "\n",
    "    ### mask FC with wetness\n",
    "\n",
    "    fc_ds_noTCW=fc_ds.where(tcw==False)\n",
    "\n",
    "    ### Calculate number of pixels in area of interest\n",
    "\n",
    "    #number of pixels in area of interest\n",
    "    pixels = (mask_xr==0).sum(dim=['x','y'])\n",
    "\n",
    "    mask_xr==0\n",
    "    mask_xr.count(dim=['x','y'])\n",
    "\n",
    "    #count number of wofs pixels\n",
    "    wofs_pixels = wetwofl.water.sum(dim=['x','y'])\n",
    "\n",
    "    #count percentage of area of wofs\n",
    "    wofs_area_percent = (wofs_pixels/pixels)*100\n",
    "\n",
    "    #count number of tcw pixels\n",
    "    tcw_pixel_count = tcw.sum(dim=['x','y'])\n",
    "\n",
    "    #calculate percentage area wet\n",
    "    tcw_area_percent = (tcw_pixel_count/pixels)*100\n",
    "\n",
    "    #calculate wet not wofs\n",
    "    tcw_less_wofs = tcw_area_percent-wofs_area_percent\n",
    "\n",
    "    ### Calculate the dominant fraction for each pixel in Fractional Cover\n",
    "\n",
    "    #drop data percentage and Unmixing Error\n",
    "    fc_tester = fc_ds_noTCW.drop(['data_perc','UE'])\n",
    "\n",
    "    #following robbi's advice, cast the dataset to a dataarray\n",
    "    maxFC = fc_tester.to_array(dim='variable', name='maxFC')\n",
    "\n",
    "    #turn FC array into integer only as nanargmax doesn't seem to handle floats the way we want it to\n",
    "    FC_int = maxFC.astype('int8')\n",
    "\n",
    "    #use numpy.nanargmax to get the index of the maximum value along the variable dimension\n",
    "    #BSPVNPV=np.nanargmax(FC_int, axis=0)\n",
    "    BSPVNPV=FC_int.argmax(dim='variable')\n",
    "\n",
    "    FC_mask=xr.ufuncs.isfinite(maxFC).all(dim='variable')\n",
    "\n",
    "    # #re-mask with nans to remove no-data\n",
    "    BSPVNPV=BSPVNPV.where(FC_mask)\n",
    "\n",
    "\n",
    "    FC_dominant = xr.Dataset({\n",
    "        'BS': (BSPVNPV==0).where(FC_mask),\n",
    "        'PV': (BSPVNPV==1).where(FC_mask),\n",
    "        'NPV': (BSPVNPV==2).where(FC_mask),\n",
    "    })\n",
    "\n",
    "    FC_count = FC_dominant.sum(dim=['x','y'])\n",
    "\n",
    "    #Fractional cover pixel count method\n",
    "    #Get number of FC pixels, divide by total number of pixels per polygon\n",
    "\n",
    "    Bare_soil_percent=(FC_count.BS/pixels)*100\n",
    "\n",
    "    Photosynthetic_veg_percent=(FC_count.PV/pixels)*100\n",
    "\n",
    "    NonPhotosynthetic_veg_percent=(FC_count.NPV/pixels)*100\n",
    "\n",
    "    NoData = 100 - wofs_area_percent- tcw_less_wofs - Photosynthetic_veg_percent - NonPhotosynthetic_veg_percent - Bare_soil_percent\n",
    "\n",
    "    query['time'][0]\n",
    "\n",
    "    #set up color palette\n",
    "    pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "           sns.xkcd_rgb[\"neon blue\"],\n",
    "           sns.xkcd_rgb[\"grass\"],\n",
    "           sns.xkcd_rgb[\"beige\"],\n",
    "           sns.xkcd_rgb[\"brown\"]]#,\n",
    "          #sns.xkcd_rgb[\"grey\"]]\n",
    "\n",
    "    #make a stacked area plot\n",
    "    plt.clf()\n",
    "    plt.figure(figsize = (12,6))\n",
    "    plt.stackplot(wofs_area_percent.time.values, \n",
    "                  wofs_area_percent, \n",
    "                  tcw_less_wofs, \n",
    "                  Photosynthetic_veg_percent, \n",
    "                  NonPhotosynthetic_veg_percent,\n",
    "                  Bare_soil_percent,\n",
    "                  NoData,\n",
    "                  labels=['open water',\n",
    "                          'wet',\n",
    "                          'PV',\n",
    "                          'NPV',\n",
    "                          'BS'#,\n",
    "                          #'NoData'\n",
    "                         ], colors=pal, alpha = 0.6)\n",
    "\n",
    "    plt.title('Percentage of area WOfS, Wetness, Fractional Cover')\n",
    "\n",
    "    #set axis limits to the min and max\n",
    "    plt.axis(xmin = query['time'][0], xmax = query['time'][1], ymin = 0, ymax = 100)\n",
    "\n",
    "    #set date ticks every year\n",
    "    years = mdates.YearLocator(2)\n",
    "    yearsFmt = mdates.DateFormatter('%Y')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(yearsFmt)\n",
    "\n",
    "    #add a legend and a tight plot box\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save the figure\n",
    "    plt.savefig(f'{Output_dir}{polyName}.png')#, transparent=True)\n",
    "    print(f'plot created for {polyName}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g/data/r78/rjd547/Ramsar_Wetlands/Ramsar_Outputs_1/Cobourg_Peninsula-Cobourg_Peninsula-NT-8.png\n"
     ]
    }
   ],
   "source": [
    "print(f'{Output_dir}{polyName}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Mainline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing polygon Cobourg_Peninsula-Cobourg_Peninsula-NT-0\n",
      "Loading ls5\n",
      "    Loading 259 filtered ls5 timesteps\n",
      "Loading ls7\n",
      "    Ignoring SLC-off observations for ls7\n",
      "    Loading 52 filtered ls7 timesteps\n",
      "Loading ls8\n",
      "    Loading 85 filtered ls8 timesteps\n",
      "Combining and sorting ls5, ls7, ls8 data\n",
      "    Replacing invalid -999 values with NaN (data will be coerced to float64)\n",
      "Loading ls5\n",
      "    Loading 259 filtered ls5 timesteps\n",
      "Loading ls7\n",
      "    Ignoring SLC-off observations for ls7\n",
      "    Loading 52 filtered ls7 timesteps\n",
      "Loading ls8\n",
      "    Loading 85 filtered ls8 timesteps\n",
      "Combining and sorting ls5, ls7, ls8 data\n",
      "    Replacing invalid -999 values with NaN (data will be coerced to float64)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b01710383ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapessubset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m### try to run the function once, for the shapefile and given crs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigFunkyFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;31m### if result is False ie. doesn't run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-d94580d74e63>\u001b[0m in \u001b[0;36mBigFunkyFunction\u001b[0;34m(lilshape, crs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mNoData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwofs_area_percent\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mtcw_less_wofs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mPhotosynthetic_veg_percent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mNonPhotosynthetic_veg_percent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mBare_soil_percent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m#set up color palette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "  #-----------------------------------------------------------------------#\n",
    "\n",
    "# Launch a process for each polygon.\n",
    "\n",
    "### for each shapefile in our subset of shapefiles:\n",
    "for shapes in shapessubset:\n",
    "    ### try to run the function once, for the shapefile and given crs\n",
    "    result = BigFunkyFunction(shapes, crs)\n",
    "    ### if result is False ie. doesn't run\n",
    "    if not result: \n",
    "        ### Try to run the function again\n",
    "        result = BigFunkyFunction(shapes, crs)\n",
    "    ### if that didn't work:    \n",
    "    if not result:\n",
    "        ### try for a third and last time\n",
    "        result = BigFunkyFunction(shapes, crs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
