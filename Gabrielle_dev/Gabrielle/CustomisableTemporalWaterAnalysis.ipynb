{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract customisable time-series of inundation within a polygon using Landsat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this notebook do?** \n",
    "\n",
    "This notebook uses a polygon to query all of Landsat 5, 7 and 8 data available from 1987 onward, optionally filter to drop cloudy scenes, mask out remaining cloud and invalid data, then compute one of several water indices on the data to indentify open water. The resulting dataset can then be used to generate a timeseries of total inundated pixels which is exported as both a CSV of metrics and water index/RGB images for each timestep. \n",
    "\n",
    "This methodology is a simplified version of the Digital Earth Australia _Water Area Mapping and Monitoring_ product (WAMM). WAMM maps the location of persistent waterbodies in the Australian landscape, then monitors changes to the surface area of water within each waterbody through time. For more information, see the [following Jupyter notebook](https://github.com/GeoscienceAustralia/dea-notebooks/blob/ClaireK/WaterbodyAreaMappingandMonitoring/GenerateWaterBodyPolygons.ipynb).\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`    \n",
    "\n",
    "This notebook uses three external functions called `load_clearlandsat` and `rgb`. These functions are available in the `10_Scripts` folder of the [dea-notebooks Github repository](https://github.com/GeoscienceAustralia/dea-notebooks/tree/master/10_Scripts). Note that these functions have been developed by DEA users, not the DEA development team, and so are provided without warranty. If you find an error or bug in the functions, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated function back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date:** August 2019\n",
    "\n",
    "**Author:** Robbi Bishop-Taylor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`plot`, :index:`time_series`, :index:`Landsat5`, :index:`Landsat7`, :index:`Landsat8`, :index:`load_clearlandsat`, :index:`DEAPlotting`, :index:`DEADataHandling`, :index:`Scripts`, :index:`Water index`, :index:`Band index`, :index:`MNDWI`, :index:`NDWI`, :index:`AWEI`, :index:`rgb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import sys\n",
    "import datacube\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from datacube.helpers import write_geotiff\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "\n",
    "# Import external functions from dea-notebooks using relative link to Scripts\n",
    "sys.path.append('../Scripts')\n",
    "import dea_datahandling\n",
    "import dea_plotting\n",
    "\n",
    "# Define custom functions\n",
    "def water_indices(ds, water_index='NDWI', custom_varname=None, source='Collection2'): \n",
    "    \n",
    "    \"\"\"\n",
    "    Takes an xarray dataset containing spectral bands, calculates one of a \n",
    "    series of water indices, and adds the resulting array as a new variable \n",
    "    in the original dataset.    \n",
    "\n",
    "    Last modified: July 2019\n",
    "    Author: Robbi Bishop-Taylor\n",
    "    \n",
    "    Parameters\n",
    "    ----------  \n",
    "    ds : xarray Dataset\n",
    "        A two-dimensional or multi-dimensional array with spectral bands named \n",
    "        'red', 'green', 'blue', 'nir', 'swir1' or 'swir2'. These bands are used\n",
    "        as inputs to calculate the selected water index.\n",
    "    water_index : str, optional\n",
    "        A string giving the name of the water index to calculate. Valid options:\n",
    "        'NDWI' (Normalised Difference Water Index, McFeeters 1996), \n",
    "        'MNDWI' (Modified Normalised Difference Water Index, Xu 1996), \n",
    "        'AWEI_ns (Automated Water Extraction Index - no shadows, Feyisa 2014)',\n",
    "        'AWEI_sh' (Automated Water Extraction Index - shadows, Feyisa 2014), \n",
    "        'WI' (Water Index, Fisher 2016) & 'TCW' (Tasseled Cap Wetness, Crist 1985).\n",
    "        Defaults to 'NDWI'.        \n",
    "    custom_varname : str, optional\n",
    "        By default, the function will return the original dataset with a new\n",
    "        water index variable named after `water_index` (e.g. NDWI). To specify\n",
    "        a custom name instead, you can supply e.g. `custom_varname='water_index'`. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray Dataset\n",
    "        The original xarray Dataset inputted into the function, with a new band\n",
    "        containing the water index DataArray.\n",
    "    \"\"\"           \n",
    "   \n",
    "    # Dictionary containing water index band recipes\n",
    "    water_index_dict = {# Normalised Difference Water Index, McFeeters 1996\n",
    "                        'NDWI': lambda ds: (ds.green - ds.nir) / (ds.green + ds.nir),\n",
    "        \n",
    "                        # Modified Normalised Difference Water Index, Xu 2006\n",
    "                        'MNDWI': lambda ds: (ds.green - ds.swir1) / (ds.green + ds.swir1),\n",
    "        \n",
    "                        # Automated Water Extraction Index (no shadows), Feyisa 2014\n",
    "                        'AWEI_ns': lambda ds: (4 * (ds.green - ds.swir1) -\n",
    "                                               (2.5 * ds.nir * + 2.75 * ds.swir2)),\n",
    "        \n",
    "                        # Automated Water Extraction Index (shadows), Feyisa 2014\n",
    "                        'AWEI_sh': lambda ds: (ds.blue + 2.5 * ds.green - \n",
    "                                               1.5 * (ds.nir + ds.swir1) - 2.5 * ds.swir2),\n",
    "    \n",
    "                        # Water Index, Fisher 2016\n",
    "                        'WI': lambda ds: (1.7204 + 171 * ds.green + 3 * ds.red + \n",
    "                                          70 * ds.nir - 45 * ds.swir1 - 71 * ds.swir2),\n",
    "        \n",
    "                        # Tasseled Cap Wetness, Crist 1985\n",
    "                        'TCW': lambda ds: (0.0315 * ds.blue + 0.2021 * ds.green + \n",
    "                                           0.3102 * ds.red + 0.1594 * ds.nir - \n",
    "                                           0.6806 * ds.swir1 - 0.6109 * ds.swir2)} \n",
    "    \n",
    "    # Select a water index function based on 'water_index'    \n",
    "    water_index_func = water_index_dict[water_index]\n",
    "    \n",
    "    # Rename bands to a consistent format if either 'Collection3'\n",
    "    # or 'Sentinel2' is specified by `source`\n",
    "    if source == 'Collection3':\n",
    "        \n",
    "        # Dictionary mapping full data names to simpler 'red' alias names\n",
    "        bandnames_dict = {'nbart_red': 'red', 'nbart_green': 'green',\n",
    "                          'nbart_blue': 'blue', 'nbart_nir': 'nir',\n",
    "                          'nbart_swir_1': 'swir1', 'nbart_swir_2': 'swir2',\n",
    "                          'nbar_red': 'red', 'nbar_green': 'green',\n",
    "                          'nbar_blue': 'blue', 'nbar_nir': 'nir', \n",
    "                          'nbar_swir_1': 'swir1', 'nbar_swir_2': 'swir2'}\n",
    "\n",
    "        # Rename bands in dataset to use simple names (e.g. 'red')\n",
    "        bands_to_rename = {a: b for a, b in bandnames_dict.items() if a in ds.variables}\n",
    "        \n",
    "    elif source == 'Sentinel2':\n",
    "        \n",
    "        # Dictionary mapping full data names to simpler 'red' alias names\n",
    "        bandnames_dict = {'nbart_red': 'red', 'nbart_green': 'green',\n",
    "                          'nbart_blue': 'blue', 'nbart_nir': 'nir',\n",
    "                          'nbart_swir_2': 'swir1', 'nbart_swir_3': 'swir2',\n",
    "                          'nbar_red': 'red', 'nbar_green': 'green',\n",
    "                          'nbar_blue': 'blue', 'nbar_nir': 'nir',\n",
    "                          'nbar_swir_2': 'swir1', 'nbar_swir_3': 'swir2'}\n",
    "\n",
    "        # Rename bands in dataset to use simple names (e.g. 'red')\n",
    "        bands_to_rename = {a: b for a, b in bandnames_dict.items() if a in ds.variables}\n",
    "\n",
    "    elif source == 'Collection2':\n",
    "        \n",
    "        # For the DEA Collection 2, pass an empty dict as no bands need renaming\n",
    "        bands_to_rename = {}\n",
    "\n",
    "    \n",
    "    # Apply water index function to data and add to input dataset. If a custom name\n",
    "    # is supplied for the output water index variable, use it.\n",
    "    if custom_varname:        \n",
    "        \n",
    "        # Apply function after normalising to a 0.0-1.0 range by dividing by 10,000\n",
    "        ds[custom_varname] = water_index_func(ds.rename(bands_to_rename) / 10000.0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Apply function after normalising to a 0.0-1.0 range by dividing by 10,000\n",
    "        ds[water_index] = water_index_func(ds.rename(bands_to_rename) / 10000.0)\n",
    "    \n",
    "    # Return input dataset with added water index variable\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up required parameters\n",
    "All parameters that need to be modified are listed below. The default values will load 25m resolution Landsat data for an example polygon, keeping only images with more than 90% cloud free pixels. These images will then be classified into water vs non-water using the `MNDWI` index using a threshold of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time range including a from and to date to load data. Can be in the format \n",
    "# ('1995', '2003'), ('1995-01', '2003-12') or ('1995-01-01', '2003-12-30')\n",
    "time_range = ('1988', '2019')\n",
    "\n",
    "# A path to the polygon used to extract data from the datacube\n",
    "polygon_path = '../Supplementary_data/Files/WA_example_waterbody.shp'\n",
    "\n",
    "# The projection system you wish to load the data in; default is 'EPSG:3577'\n",
    "output_crs = 'EPSG:3577'\n",
    "\n",
    "# The resolution you wish to load the data at; default for Landsat is '(-25, 25)'\n",
    "output_res = (-25, 25)\n",
    "\n",
    "# The minimum proportion of valid non-cloudy pixels used to decide what images \n",
    "# to load. A value of 0.9 will only load images with less than 10% cloud/cloud shadow.\n",
    "min_clearprop = 0.90\n",
    "\n",
    "# Water index used to identify inundated pixels. Valid options include 'NDWI' (Normalised \n",
    "# Difference Water Index, McFeeters 1996), 'MNDWI' (Modified Normalised Difference Water \n",
    "# Index, Xu 1996), 'AWEI_ns (Automated Water Extraction Index - no shadows, Feyisa 2014)',\n",
    "# 'AWEI_sh' (Automated Water Extraction Index - shadows, Feyisa 2014), 'WI' (Water Index, \n",
    "# Fisher 2016) & 'TCW' (Tasseled Cap Wetness, Crist 1985).\n",
    "water_index = 'MNDWI'\n",
    "\n",
    "# Water index threshold used to identify inundated pixels based on the specified water index\n",
    "water_index_thresh = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in polygon\n",
    "Read in an example polygon from file, re-project it to match the desired output CRS, and prepare it to extract data from the datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "../Supplementary_data/Files/WA_example_waterbody.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../Supplementary_data/Files/WA_example_waterbody.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7d74db4a3ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in polygon from file into a geopandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwaterbody_polygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Re-project polygon to match desired output CRS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwaterbody_polygon_albers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaterbody_polygon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_crs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0;32m--> 257\u001b[0;31m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: ../Supplementary_data/Files/WA_example_waterbody.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Read in polygon from file into a geopandas dataframe\n",
    "waterbody_polygon = gpd.read_file(polygon_path)\n",
    "\n",
    "# Re-project polygon to match desired output CRS\n",
    "waterbody_polygon_albers = waterbody_polygon.to_crs({'init': output_crs})\n",
    "waterbody_polygon_albers.plot()\n",
    "\n",
    "# Use the polygon to create a custom datacube geometry object based on \n",
    "# geojson and projection. This is used as in input to the datacube load.\n",
    "geom = geometry.Geometry(waterbody_polygon_albers.iloc[0].geometry.__geo_interface__, \n",
    "                         crs=geometry.CRS(output_crs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Digital Earth Australia datacube\n",
    "Here we use the `load_clearlandsat` function to extract a timeseries of Landsat data from the Landsat 5, 7 and 8 satellites. By default, we include the entire Landsat timeseries including images taken after the 2003 Landsat 7 SLC-off failure (to remove this, set `ls7_slc_off=True` to `ls7_slc_off=False`). The function keeps only images containing a minimum percentage of cloud-free pixels, and combines data from the three satellites into a single dataset with cloudy/invalid pixels marked as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to datacube database\n",
    "dc = datacube.Datacube(app='Customisable water analysis')\n",
    "\n",
    "# Loading data from the datacube requires a spatiotemporal query that informs\n",
    "# the datacube of the area, time period and other parameters used to load the data\n",
    "query = {'geopolygon': geom,   \n",
    "         'time': time_range,\n",
    "         'output_crs': output_crs,\n",
    "         'resolution': output_res} \n",
    "\n",
    "# Set up a custom dictionary which tells the `load_clearlandsat` function what\n",
    "# pixels to mark as being 'unclear' based on the Landsat's pixel quality data.\n",
    "# We do not include the `'contiguous': True` argument here, because this causes\n",
    "# Landsat 7 SLC-off observations to be dropped before they are loaded (see below)\n",
    "mask_dict = {'cloud_acca': 'no_cloud', \n",
    "             'cloud_shadow_acca': 'no_cloud_shadow', \n",
    "             'cloud_shadow_fmask': 'no_cloud_shadow', \n",
    "             'cloud_fmask': 'no_cloud', \n",
    "             'blue_saturated': False, \n",
    "             'green_saturated': False, \n",
    "             'red_saturated': False, \n",
    "             'nir_saturated': False, \n",
    "             'swir1_saturated': False, \n",
    "             'swir2_saturated': False}\n",
    "\n",
    "# The 'load_clearlandsat' function loads a subset of images from all of Landsat 5, 7\n",
    "# and 8 based on their cloudiness, and returns a single combined dataset where all \n",
    "# remaining cloudy pixels are masked out as NAN values\n",
    "landsat_ds = DEADataHandling.load_clearlandsat(dc=dc, \n",
    "                                               query=query,\n",
    "                                               sensors=['ls5', 'ls7', 'ls8'],\n",
    "                                               masked_prop=min_clearprop, \n",
    "                                               mask_pixel_quality=True,\n",
    "                                               mask_invalid_data=True,\n",
    "                                               mask_dict=mask_dict,\n",
    "                                               ls7_slc_off=True)\n",
    "\n",
    "# Typically, we use a pixel quality flag `'contiguous': True` to mask out pixels which \n",
    "# have NA values in any of their spectral bands. However, this has the unintended side \n",
    "# effect of causing SLC-off LS7 scenes to be dropped, as the function considers them to \n",
    "# contain many missing/unclear values. As a workaround, we identify pixels with missing \n",
    "# values *after* we load the data by testing if each pixel contains valid values in all \n",
    "# six spectral bands. We can then use this mask to remove these pixels from our data:\n",
    "is_valid = landsat_ds.drop('data_perc').to_array().count(dim='variable') == 6\n",
    "landsat_ds = landsat_ds.where(is_valid)\n",
    "\n",
    "# Print the dataset that is loaded from the datacube\n",
    "print(landsat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example timestep in RGB\n",
    "DEAPlotting.rgb(landsat_ds, index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate water index \n",
    "We use the `water_indices` function to calculate a water index based on the loaded Landsat bands. By default, we use the Modified Normalised Difference Water Index ('MNDWI') to identify open water, however valid options are listed below (see `Set up required parameters`):\n",
    "- NDWI (Normalised Difference Water Index, McFeeters 1996)\n",
    "- MNDWI (Modified Normalised Difference Water, Index, Xu 1996)\n",
    "- AWEI_ns (Automated Water Extraction Index - no shadows, Feyisa 2014)\n",
    "- AWEI_sh (Automated Water Extraction Index - shadows, Feyisa 2014)\n",
    "- WI (Water Index, Fisher 2016)\n",
    "- TCW (Tasseled Cap Wetness, Crist 1985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the `water_indices` function to apply a water index of choice to the\n",
    "# Landsat dataset. The new index will appear as a new generically named \n",
    "# 'water_index' variable in the dataset\n",
    "landsat_ds = water_indices(landsat_ds, \n",
    "                           water_index=water_index, \n",
    "                           custom_varname='water_index')\n",
    "\n",
    "# Plot result of the water index calculation\n",
    "landsat_ds.water_index.isel(time=1).plot(cmap='RdBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask out area outside polygon\n",
    "To focus on the area of the actual waterbody to calculate inundation statistics, we mask out pixels located outside the polygon boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rasterio.features.rasterize(shapes=[(waterbody_polygon_albers.iloc[0].geometry, 1)],\n",
    "                                   out_shape=(landsat_ds.dims['y'], landsat_ds.dims['x']),\n",
    "                                   transform=landsat_ds.geobox.transform)\n",
    "\n",
    "# Apply raster mask to dataset. This will automatically apply the mask to \n",
    "# all timesteps and bands in the dataset.\n",
    "landsat_masked = landsat_ds.where(mask)\n",
    "\n",
    "# Plot a single timestep in RGB to verify that data outside the polygon has been masked out\n",
    "DEAPlotting.rgb(landsat_masked, index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export inundation metrics\n",
    "Using the masked dataset created above, we can now calculate overall inundation statistics for every timestep in the dataset. We calculate four overall metric types: the total number of pixels/area within the polygon, the total number of inundated pixels/area, the total number of dry pixels/area, and the total number of nodata/NaN pixels/area. Finally, our output statistics are saved to file as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total, inundated, dry and NA stats across the timeseries\n",
    "pxct = mask.sum()  # get total pixels from polygon mask area\n",
    "pxin = (landsat_masked.water_index >= water_index_thresh).sum(dim=['x', 'y'])\n",
    "pxha = (landsat_masked.water_index < water_index_thresh).sum(dim=['x', 'y'])\n",
    "pxna = pxct - pxin - pxha  # nodata pixels = total - wet - dry\n",
    "\n",
    "# Compute areas in hectares by multiplying by square metres and dividing by 10000 for ha\n",
    "toha = pxct * np.abs(output_res[0] * output_res[1]) / 10000.0\n",
    "inha = pxin * np.abs(output_res[0] * output_res[1]) / 10000.0\n",
    "drha = pxha * np.abs(output_res[0] * output_res[1]) / 10000.0\n",
    "naha = pxna * np.abs(output_res[0] * output_res[1]) / 10000.0\n",
    "\n",
    "# Add to a single dataframe ready to be written out as a CSV with time as an index\n",
    "wateranalysis_df = pd.DataFrame(data={'pxct': pxct, 'pxin': pxin, 'pxha': pxha, 'pxna': pxna, \n",
    "                                      'toha': toha, 'inha': inha, 'drha': drha, 'naha': naha },\n",
    "                                index=landsat_masked.time.values)\n",
    "\n",
    "# Write to file\n",
    "wateranalysis_df.to_csv(f'rel_indundation_{time_range[0]}-{time_range[1]}.csv', index_label='time')\n",
    "\n",
    "# Preview data\n",
    "wateranalysis_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "Plot some simple summary plots showing patterns of inundation across time for the polygon being analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a stacked area plot containing all three categories\n",
    "wateranalysis_df[['inha', 'drha', 'naha']].plot.area(color=['#73abfa', '#ffd79c', '#6b6b6b'], \n",
    "                                                     linewidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a normalised inundation percent based on proportion of valid area that was innundated\n",
    "percent_inundation = wateranalysis_df.inha / (wateranalysis_df.toha - wateranalysis_df.naha)\n",
    "percent_inundation.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export RGB and water index images and geotiffs\n",
    "Finally, we export some accompanying images to help interpret the metrics in the CSV. This includes an RGB image and a water index image for each timestep in the dataset. Optionally, we can also export a geotiff file for each timestep for both the RGB bands and the water index variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time, i in landsat_ds.groupby('time'):\n",
    "    \n",
    "    ####################\n",
    "    # Plot water index #\n",
    "    ####################\n",
    "    \n",
    "    # Plot water index\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(i.water_index.values, \n",
    "              cmap='RdBu',\n",
    "              extent=[i.extent.boundingbox[x] for x in [0, 2, 1, 3]],\n",
    "              vmin=-1.0, vmax=1.0)\n",
    "    \n",
    "    # Add polygon as an overlay over the top of the image\n",
    "    waterbody_polygon_albers.plot(ax=ax, facecolor='None', \n",
    "                                  edgecolor='black', linestyle='--')\n",
    "    \n",
    "    # Export water index image to file\n",
    "    water_index_png = f'd{str(time)[0:10]}_{water_index}.png'\n",
    "    fig.savefig(water_index_png, bbox_inches='tight')\n",
    "    \n",
    " \n",
    "    ############\n",
    "    # Plot RGB #\n",
    "    ############\n",
    "    \n",
    "    # To plot the RGB array, first we need to load it\n",
    "    # as a 3D numpy array with bands as the final axis\n",
    "    rgb_array = np.transpose(i[['red', 'green', 'blue']]\n",
    "                             .to_array()\n",
    "                             .values, \n",
    "                             axes=[1, 2, 0])\n",
    "    \n",
    "    # Divide by 3000 to keep values between 0 and 1,\n",
    "    # and create a reasonably good colour stretch\n",
    "    rgb_array = (rgb_array / 3000).clip(0, 1)\n",
    "    \n",
    "    # Plot RGB array\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(rgb_array, \n",
    "              extent=[i.extent.boundingbox[x] for x in [0, 2, 1, 3]])\n",
    "    \n",
    "    # Add polygon as an overlay over the top of the image\n",
    "    waterbody_polygon_albers.plot(ax=ax, facecolor='None', \n",
    "                                  edgecolor='black', linestyle='--')\n",
    "    \n",
    "    # Export RGB image to file\n",
    "    rgb_png = f'd{str(time)[0:10]}_rgb.png'\n",
    "    fig.savefig(rgb_png, bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    ######################################\n",
    "    # OPTIONAL - export geotiffs to file #\n",
    "    ######################################\n",
    "    \n",
    "#     water_index_tif = f'd{str(time)[0:10]}_{water_index}.tif'\n",
    "#     rgb_tif = f'd{str(time)[0:10]}_rgb.tif'\n",
    "#     write_geotiff(filename=water_index_tif, dataset=i[['water_index']]) \n",
    "#     write_geotiff(filename=rgb_tif, dataset=i[['red', 'green', 'blue']]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
