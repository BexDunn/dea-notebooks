{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractional Cover Collection 3 Validation\n",
    "\n",
    "This notebook generates plots and statistics comparing Fractional Cover Collection 2 (FC2) and 3 (FC3). The plots are:\n",
    "\n",
    "- a triangle plot for FC2 and 3 for each scene and all combined scenes\n",
    "- a plot showing the spatial difference for each FC band between Collection 2 and 3 for each scene and the all-time median\n",
    "\n",
    "The statistics are:\n",
    "\n",
    "- The number of pixels along the triangle edges (scene and total) i.e. the number of saturated FC pixels\n",
    "- The mean difference between FC2 and FC3 in FC-space (scene and total)\n",
    "- The standard defviation of the difference between FC2 and FC3 in FC-space (scene and total)\n",
    "\n",
    "Each of these plots and statistics will be calculated for each Landsat satellite separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Import some modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from odc.ui import with_ui_cbk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../Scripts')\n",
    "import dea_datahandling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datacube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"FC3Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "Location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northern Territory\n",
    "latitudes = (-18.36, -18.56)\n",
    "longitudes = (134.00, 134.20)\n",
    "\n",
    "# # West Tasmania\n",
    "# latitudes = (-42.18, -42.28)\n",
    "# longitudes = (145.48, 145.68)\n",
    "\n",
    "# # Toowoomba\n",
    "# latitudes = (-27.31, -27.41)\n",
    "# longitudes = (151.01, 151.12)\n",
    "\n",
    "# Menindee\n",
    "# longitudes = 142.138830, 142.502419\n",
    "# latitudes = -32.512952, -32.174746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('1988', '2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of interpolation to use for plotting spatial FC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 'gaussian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fractional cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a query for each Landsat platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {i: {\n",
    "    \"resolution\": (-30, 30),\n",
    "    \"group_by\": \"solar_day\",\n",
    "#     \"region_code\": \"090079\",\n",
    "    'platform': f'landsat-{i}',\n",
    "    \"lat\": latitudes,\n",
    "    \"lon\": longitudes,\n",
    "    \"time\": time,\n",
    "} for i in [5, 7, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = {5: 'ga_ls5t_ard_3', 7: 'ga_ls7e_ard_3', 8: 'ga_ls8c_ard_3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crs(*args, **kwargs):\n",
    "    \"\"\"Wrapper for dea_datahandling.mostcommon_crs which catches exceptions and returns a default CRS.\"\"\"\n",
    "    try:\n",
    "        return dea_datahandling.mostcommon_crs(*args, **kwargs)\n",
    "    except IndexError:\n",
    "        return 'EPSG:3577'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_crs = {i: get_crs(dc, p, query[i]) for i, p in products.items()}\n",
    "for i in products:\n",
    "    query[i]['output_crs'] = output_crs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FC3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c279988c44504badb22d998cd597d41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cdac209d774e0595ea472688704f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51daa64da8c348ae8a254ccc0bb4f29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_fc3 = {i: dc.load(\n",
    "    product=\"ga_ls_fc_3\",\n",
    "    **query[i],\n",
    "    resampling=\"bilinear\",\n",
    "    progress_cbk=with_ui_cbk(),\n",
    "    dask_chunks={},\n",
    ") for i in products}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load FC2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fc2 = {i: dc.load(\n",
    "    product=f\"ls{i}_fc_albers\",\n",
    "    **{k: v for k, v in query[i].items() if k not in {'lon', 'lat', 'platform', \n",
    "                                                      'region_code', 'output_crs', 'resolution'}},\n",
    "    like=ds_fc3[i],\n",
    "    resampling=\"bilinear\",\n",
    "    dask_chunks={},\n",
    ") for i in products}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load C3 ARD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ard3 = {i: dc.load(\n",
    "    product=products[i],\n",
    "    **{k: v for k, v in query[i].items() if k not in {'lon', 'lat', 'platform', \n",
    "                                                      'region_code', 'output_crs', 'resolution'}},\n",
    "    like=ds_fc3[i],\n",
    "    resampling=\"bilinear\",\n",
    "    dask_chunks={},\n",
    ") for i in products}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which have data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_data = {i: len(ds_fc3[i]) > 0 for i in products}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a WOfS mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load WOfS from Collection 3 to mask both datasets. This keeps the mask the same so they can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d97bd8ee25476197efa42918be46c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f37d58de02449b199aafb8fb6339c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ce81ef26884659983b161fa532ccb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wofs = {i: dc.load(\n",
    "    product=f\"ga_ls_wo_3\",\n",
    "    **{k: v for k, v in query[i].items() if k not in {'lon', 'lat', 'platform', \n",
    "                                                      'region_code', 'output_crs', 'resolution'}},\n",
    "    like=ds_fc3[i],\n",
    "    resampling=\"nearest\",\n",
    "    progress_cbk=with_ui_cbk(),\n",
    "    dask_chunks={},\n",
    ") if has_data[i] else ds_fc3[i] for i in products}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wofs_mask = {i: wofs[i] == 0 for i in products}  # Dry and clear only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align time for Collection 2 and Collection 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove milliseconds to make data comparable\n",
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    ds_fc2[i][\"time\"] = ds_fc2[i].indexes[\"time\"].normalize()\n",
    "    ds_fc3[i][\"time\"] = ds_fc3[i].indexes[\"time\"].normalize()\n",
    "    wofs_mask[i][\"time\"] = wofs_mask[i].indexes[\"time\"].normalize()\n",
    "    ds_ard3[i][\"time\"] = ds_ard3[i].indexes[\"time\"].normalize()\n",
    "\n",
    "    ds_fc3[i] = ds_fc3[i].sel(time=~ds_fc3[i].indexes['time'].duplicated(keep='first'))\n",
    "    ds_fc2[i] = ds_fc2[i].sel(time=~ds_fc2[i].indexes['time'].duplicated(keep='first'))\n",
    "    ds_ard3[i] = ds_ard3[i].sel(time=~ds_ard3[i].indexes['time'].duplicated(keep='first'))\n",
    "    wofs_mask[i] = wofs_mask[i].sel(time=~wofs_mask[i].indexes['time'].duplicated(keep='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[~df.index.duplicated(keep='first')]\n",
    "# Remove duplicate time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match timesteps\n",
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    ds_compare = sorted(set(ds_fc3[i].time[ds_fc3[i][\"time\"].isin(ds_fc2[i][\"time\"].values) & ds_fc3[i][\"time\"].isin(ds_ard3[i][\"time\"].values)].values))\n",
    "    ds_fc3_sel = ds_fc3[i].sel(time=ds_compare)\n",
    "    ds_fc2_sel = ds_fc2[i].sel(time=ds_compare)\n",
    "    ds_ard3_sel = ds_ard3[i].sel(time=ds_compare)\n",
    "#         ds_fc2_sel = ds_fc2[i].where(ds_fc2[i].time == ds_fc3[i].time)\n",
    "    ds_fc3[i] = ds_fc3_sel\n",
    "    ds_fc2[i] = ds_fc2_sel\n",
    "    ds_ard3[i] = ds_ard3_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Collection 2 variables to match Collection 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    ds_fc2[i] = ds_fc2[i].rename_vars({\"BS\": \"bs\", \"PV\": \"pv\", \"NPV\": \"npv\", \"UE\": \"ue\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the nodata with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each product has a different nodata value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 255 -999 0\n",
      "-1 255 -999 0\n",
      "-1 255 -999 0\n"
     ]
    }
   ],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    print(\n",
    "        ds_fc2[i].bs.nodata,\n",
    "        ds_fc3[i].bs.nodata,\n",
    "        ds_ard3[i].nbart_red.nodata,\n",
    "        ds_ard3[i].oa_fmask.nodata,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So mask each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    ds_fc2[i] = ds_fc2[i].where(ds_fc2[i] != -1)\n",
    "    ds_fc3[i] = ds_fc3[i].where(ds_fc3[i] != 255)\n",
    "    ds_ard3[i] = ds_ard3[i].where(ds_ard3[i] != -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then mask by WOfS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    ds_fc2[i] = ds_fc2[i].where(wofs_mask[i].water)\n",
    "    ds_fc3[i] = ds_fc3[i].where(wofs_mask[i].water)\n",
    "    ds_ard3[i] = ds_ard3[i].where(wofs_mask[i].water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of spatial medians\n",
    "\n",
    "We'll take the median of each stack of FC and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd038f050b944fc580cbc574b820c7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(products):\n",
    "    ds_fc2[i].load()\n",
    "    ds_fc3[i].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T07:01:27.115536Z",
     "start_time": "2018-08-29T07:01:27.111107Z"
    }
   },
   "outputs": [],
   "source": [
    "median_fc2 = {i: ds_fc2[i].median(dim='time') if has_data[i] else ds_fc2[i] for i in products}\n",
    "median_fc3 = {i: ds_fc3[i].median(dim='time') if has_data[i] else ds_fc3[i] for i in products}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(products, position=0):\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    fig, axs = plt.subplots(4, 3, figsize=(20, 18))\n",
    "    fig.suptitle(f'Landsat {i}', y=1.02)\n",
    "    # Plot the FC2 and FC3 medians:\n",
    "    for j, band in enumerate(tqdm(['pv', 'npv', 'bs', 'ue'], position=1, leave=False)):\n",
    "        # FC2\n",
    "        median_fc2[i][band].plot.imshow(ax=axs[j, 0], interpolation=interpolation, vmin=0, vmax=100)\n",
    "        # FC3\n",
    "        median_fc3[i][band].plot.imshow(ax=axs[j, 1], interpolation=interpolation, vmin=0, vmax=100)\n",
    "        # Difference\n",
    "        (median_fc3[i][band] - median_fc2[i][band]).plot.imshow(ax=axs[j, 2], interpolation=interpolation, vmin=-10, vmax=10, cmap='coolwarm')\n",
    "        \n",
    "        axs[j, 0].set_title(f'{band.upper()} / Collection 2')\n",
    "        axs[j, 1].set_title(f'{band.upper()} / Collection 3')\n",
    "        axs[j, 2].set_title(f'{band.upper()} / Collection 3 - Collection 2')\n",
    "    plt.savefig(f'../outputs/FC3_means_NT_Landsat{i}.png')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-time linear comparison plot\n",
    "\n",
    "Another way we can compare FC between collections is to see how each band compares on a pixel-by-pixel basis. Let's plot them against each other. If the collections are identical, this should be a thin straight line; if they're identical up to noise, this should be a wide straight line.\n",
    "\n",
    "There's a lot of points, so it's quite hard to visualise. We'll look at the first and ninety-ninth percentiles as well as the medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(products, position=0):\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axs = [ax for axs_ in axs for ax in axs_]\n",
    "    fig.suptitle(f'Landsat {i}', y=1.02)\n",
    "    for j, band in enumerate(tqdm([\"pv\", \"bs\", \"npv\", \"ue\"], position=1, leave=False)):\n",
    "        fc2 = ds_fc2[i][band].values.ravel()\n",
    "        fc3 = ds_fc3[i][band].values.ravel()\n",
    "\n",
    "        # add some noise to help visualise, because FC rounds to integers\n",
    "        fc2 = fc2 + np.random.normal(0, 0.5, size=fc2.shape)\n",
    "        fc3 = fc3 + np.random.normal(0, 0.5, size=fc3.shape)\n",
    "        \n",
    "        step = 2\n",
    "        xs = []\n",
    "        ys_99 = []\n",
    "        ys_90 = []\n",
    "        ys_50 = []\n",
    "        ys_10 = []\n",
    "        ys_01 = []\n",
    "        for x_min in np.arange(0, 100, step):\n",
    "            in_x_range = (fc2 >= x_min) & (fc2 < x_min + step)\n",
    "            matching_fc2 = fc2[in_x_range]\n",
    "            matching_fc3 = fc3[in_x_range]\n",
    "            if len(matching_fc3) == 0:\n",
    "                continue\n",
    "            xs.append(np.median(matching_fc2))\n",
    "            ys_99.append(np.percentile(matching_fc3, 99))\n",
    "            ys_90.append(np.percentile(matching_fc3, 90))\n",
    "            ys_50.append(np.percentile(matching_fc3, 50))\n",
    "            ys_10.append(np.percentile(matching_fc3, 10))\n",
    "            ys_01.append(np.percentile(matching_fc3, 1))\n",
    "\n",
    "        axs[j].plot(xs, ys_50, c='C0')\n",
    "        axs[j].fill_between(xs, ys_01, ys_99, color='C0', alpha=0.2)\n",
    "        axs[j].plot([0, 100], [0, 100], color=\"black\", linestyle='--')\n",
    "        axs[j].set_title(band.upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the properties of the linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    \n",
    "    for j, band in enumerate([\"pv\", \"bs\", \"npv\", \"ue\"]):\n",
    "        fc2 = ds_fc2[i][band].values.ravel()\n",
    "        fc3 = ds_fc3[i][band].values.ravel()\n",
    "        yes_nan = np.isnan(fc2) | np.isnan(fc3)\n",
    "        lr = scipy.stats.linregress(fc2[~yes_nan], fc3[~yes_nan])\n",
    "        print(f'Landsat {i} / {band.upper():>3}: R^2 = {lr.rvalue ** 2:.02f}, 3σ = {3 * lr.stderr:.02e}, offset = {lr.slope:.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle plots\n",
    "\n",
    "We'll plot the FC distribution for each scene for C2 and C3, and also for all-time. We'll colour each point by its Landsat false colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_fc(fc_dataset, c3_ard, ax, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot the fractional cover triangle.\n",
    "    \"\"\"\n",
    "    A2 = np.stack([fc_dataset.pv, fc_dataset.npv, fc_dataset.bs]).astype(float)\n",
    "    R = np.array([[0, 1 / 3 ** 0.5], [-0.6, -1 / 3 ** 0.5], [0.6, -1 / 3 ** 0.5]])\n",
    "    P2 = np.tensordot(R, A2, (0,0)).reshape(2, -1)\n",
    "\n",
    "    key_points = {\n",
    "        'pv': np.array([1, 0, 0]),\n",
    "        'npv': np.array([0, 1, 0]),\n",
    "        'bs': np.array([0, 0, 1]),\n",
    "    }\n",
    "    for name, kp in key_points.items():\n",
    "        transformed = kp @ R * 100\n",
    "        offset = (kp * 20) @ R\n",
    "        ax.scatter(transformed[0], transformed[1], s=10, c='k', zorder=10)\n",
    "        ax.annotate(name, transformed, xytext=offset, textcoords='offset points', ha='center', va='center')\n",
    "    \n",
    "    colours = np.stack([c3_ard.nbart_swir_1.values.ravel(), c3_ard.nbart_nir.values.ravel(), c3_ard.nbart_green.values.ravel()])\n",
    "    \n",
    "    # Clip ARD to 2nd, 98th percentiles to enhance the colours.\n",
    "    pc_min, pc_max = np.nanpercentile(colours, [2, 98], axis=1, keepdims=True)\n",
    "    colours = np.clip(colours, pc_min, pc_max)\n",
    "    colours = colours - np.nanmin(colours)\n",
    "    colours /= np.nanmax(colours)\n",
    "    # Add some noise to avoid clumping around integers.\n",
    "    P2 = P2 + np.random.normal(0, 0.5, size=P2.shape)\n",
    "    ax.scatter(P2[0], P2[1], s=1, c=colours.T, edgecolor='None', **kwargs)\n",
    "    ax.set_xlim(-70, 70)\n",
    "    ax.set_ylim(-70, 70)\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    triangle_fc(ds_fc2[i], ds_ard3[i], axs[0], alpha=0.01)\n",
    "    axs[0].set_title(f'Landsat {i} Collection 2')\n",
    "    triangle_fc(ds_fc3[i], ds_ard3[i], axs[1], alpha=0.01)\n",
    "    axs[1].set_title(f'Landsat {i} Collection 3')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    for t in ds_fc2[i].time:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        dt = pd.to_datetime(t.values).strftime('%Y-%m-%d')\n",
    "        triangle_fc(ds_fc2[i].sel(time=t), ds_ard3[i].sel(time=t), axs[0], alpha=0.5)\n",
    "        axs[0].set_title(f'Landsat {i} Collection 2, {dt}')\n",
    "        triangle_fc(ds_fc3[i].sel(time=t), ds_ard3[i].sel(time=t), axs[1], alpha=0.5)\n",
    "        axs[1].set_title(f'Landsat {i} Collection 3, {dt}')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also animate that if you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install celluloid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate = False\n",
    "if animate:\n",
    "    # This code could be improved by using xr's interpolation instead of Pandas'.\n",
    "    ds_shape = ds_fc2[5].to_array().shape\n",
    "\n",
    "#     df_fc2 = pd.DataFrame(np.transpose(ds_fc2[5].to_array().values, (1, 0, 2, 3)).reshape(len(ds_fc2[5].time), -1), index=ds_fc2[5].time.values)  # time, band, x, y\n",
    "\n",
    "#     df_fc2 = df_fc2.resample('1W').mean()\n",
    "\n",
    "#     df_fc2 = df_fc2.interpolate(axis=0, method='time')\n",
    "\n",
    "#     resampled = ds_ard3[5].resample({'time': '1W'}).mean()\n",
    "    daterange = pd.date_range(ds_fc2[5].time.values[0], ds_fc2[5].time.values[-1], freq='1W')\n",
    "    interpolated_fc2 = ds_fc2[5].chunk({'time': -1}).interpolate_na(dim=\"time\").interp(time=daterange).chunk({'time': 1}).load()\n",
    "    interpolated = ds_ard3[5].chunk({'time': -1}).interpolate_na(dim=\"time\").interp(time=daterange).chunk({'time': 1}).load()\n",
    "\n",
    "    from tqdm.auto import tqdm\n",
    "    from celluloid import Camera\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    camera = Camera(fig)\n",
    "\n",
    "#     for t, row in tqdm(df_fc2.iterrows()):\n",
    "    for t in tqdm(interpolated_fc2.time):\n",
    "        row = interpolated_fc2.sel(time=t)#row.values.reshape(ds_shape[0], ds_shape[2], ds_shape[3])\n",
    "#         bs = xr.DataArray(row[0], dims=['y', 'x'], coords={'y': ds_fc2[5].y, 'x': ds_fc2[5].x})\n",
    "#         pv = xr.DataArray(row[1], dims=['y', 'x'], coords={'y': ds_fc2[5].y, 'x': ds_fc2[5].x})\n",
    "#         npv = xr.DataArray(row[2], dims=['y', 'x'], coords={'y': ds_fc2[5].y, 'x': ds_fc2[5].x})\n",
    "#         row = xr.Dataset({'bs': bs, 'pv': pv, 'npv': npv})\n",
    "        dt = pd.to_datetime(t.values).strftime('%Y-%m-%d')\n",
    "        triangle_fc(row, interpolated.sel(time=t, method='nearest'), ax, alpha=0.5)\n",
    "        ax.text(0.02, 0.98, dt, transform=ax.transAxes, ha='left', va='top')\n",
    "        camera.snap()\n",
    "    \n",
    "    animation = camera.animate()\n",
    "    animation.save('animation3.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference statistics\n",
    "\n",
    "Let's get the mean and standard deviation for the difference between the two collections. Again, we'll do this for each scene and for all scenes. We can also do this for the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    if verbose:\n",
    "        print(f'Landsat {i}')\n",
    "    xs = []\n",
    "    ys_mean = []\n",
    "    ys_stdev = []\n",
    "    for t in ds_fc2[i].time:\n",
    "        xs.append(t.values)\n",
    "        dt = pd.to_datetime(t.values).strftime('%Y-%m-%d')\n",
    "        diff = ds_fc2[i].sel(time=t) - ds_fc3[i].sel(time=t)\n",
    "        diff = diff[['pv', 'npv', 'bs']].to_array()\n",
    "        mean = diff.mean(axis=(1, 2))\n",
    "        stdev = diff.std(axis=(1, 2))\n",
    "        if verbose:\n",
    "            print(f'\\t{dt}')\n",
    "            for band, m, s in zip(['pv', 'npv', 'bs'], mean.values, stdev.values):\n",
    "                print(f'\\t\\t{band.upper():>3}: {m:0.2f} +- {s:.02f}')\n",
    "        ys_mean.append(mean.values)\n",
    "        ys_stdev.append(stdev.values)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(pd.to_datetime(xs), ys_mean)\n",
    "    plt.legend(['PV', 'NPV', 'BS'])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Mean offset')\n",
    "    plt.title(f'Landsat {i} / Mean offset')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(pd.to_datetime(xs), ys_stdev)\n",
    "    plt.legend(['PV', 'NPV', 'BS'])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Standard deviation of difference')\n",
    "    plt.title(f'Landsat {i} / Standard deviation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    print(f'Landsat {i} time-averaged offset')\n",
    "    diff = ds_fc2[i] - ds_fc3[i]\n",
    "    diff = diff[['pv', 'npv', 'bs']].to_array()\n",
    "    mean = diff.mean(axis=(1, 2, 3))\n",
    "    stdev = diff.std(axis=(1, 2, 3))\n",
    "    for band, m, s in zip(['pv', 'npv', 'bs'], mean.values, stdev.values):\n",
    "        print(f'\\t{band.upper():>3}: {m:0.2f} +- {s:.02f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    print(f'Landsat {i} time-averaged offset')\n",
    "    diff = ds_fc2[i] - ds_fc3[i]\n",
    "    diff = diff[['pv', 'npv', 'bs']].to_array().values.ravel()\n",
    "    plt.hist(diff, bins=np.linspace(-15, 15, 100))\n",
    "    plt.xlabel('Difference between Collection 3 and Collection 2')\n",
    "    plt.ylabel('Number of pixels')\n",
    "    plt.title(products[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    print(f'Landsat {i} (median) offset')\n",
    "    diff = median_fc2[i] - median_fc3[i]\n",
    "    diff = diff[['pv', 'npv', 'bs']].to_array()\n",
    "    mean = diff.mean(axis=(1, 2))\n",
    "    stdev = diff.std(axis=(1, 2))\n",
    "    for band, m, s in zip(['pv', 'npv', 'bs'], mean.values, stdev.values):\n",
    "        print(f'\\t{band.upper():>3}: {m:0.2f} +- {s:.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of saturated FC pixels\n",
    "\n",
    "The number of pixels exactly on the boundary of the FC triangle seems to have decreased in Collection 3. This is probably a good thing, but let's quantify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "for i in products:\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    if verbose:\n",
    "        print(f'Landsat {i}')\n",
    "    xs = []\n",
    "    ys_2 = []\n",
    "    ys_3 = []\n",
    "    for t in ds_fc2[i].time:\n",
    "        xs.append(t.values)\n",
    "        dt = pd.to_datetime(t.values).strftime('%Y-%m-%d')\n",
    "        fc2 = ds_fc2[i].sel(time=t)\n",
    "        fc3 = ds_fc3[i].sel(time=t)\n",
    "        n_boundary_fc2 = ((fc2.bs == 0) | (fc2.pv == 0) | (fc2.npv == 0)).sum()\n",
    "        n_boundary_fc3 = ((fc3.bs == 0) | (fc3.pv == 0) | (fc3.npv == 0)).sum()\n",
    "        if verbose:\n",
    "            print(f'\\t{dt}: {n_boundary_fc2} saturated in C2, {n_boundary_fc3} saturated in C3')\n",
    "        ys_2.append(n_boundary_fc2)\n",
    "        ys_3.append(n_boundary_fc3)\n",
    "    plt.figure()\n",
    "    plt.plot(pd.to_datetime(xs), ys_2, label='FC2')\n",
    "    plt.plot(pd.to_datetime(xs), ys_3, label='FC3')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Saturated FC pixels')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f'Landsat {i} C2 mean saturated FC pixels: {np.mean(ys_2):.0f} +- {np.std(ys_2):.0f}')\n",
    "    print(f'Landsat {i} C3 mean saturated FC pixels: {np.mean(ys_3):.0f} +- {np.std(ys_3):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(products):\n",
    "    if not has_data[i]:\n",
    "        continue\n",
    "    print(f'Landsat {i} time-averaged offset')\n",
    "    diff = ds_fc2[i] - ds_fc3[i]\n",
    "    diff = diff[['pv', 'npv', 'bs']].to_array().values.ravel()\n",
    "    plt.hist(diff, bins=np.linspace(-15, 15, 21))\n",
    "    plt.xlabel('Difference between Collection 3 and Collection 2')\n",
    "    plt.ylabel('Number of pixels')\n",
    "    plt.title(products[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
