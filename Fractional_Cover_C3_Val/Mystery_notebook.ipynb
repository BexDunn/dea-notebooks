{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate FC with field data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find field data;\n",
    "2. Load corresponding surface reflectance from datacube or pickle;\n",
    "3. Calculate FC and compare to field data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sensor_name\n",
    "#sensor_name = 'Landsat 8 noscaling'\n",
    "#sensor_name = 'Landsat 8 current'\n",
    "sensor_name = 'Landsat 8'\n",
    "#sensor_name = 'Landsat 7'\n",
    "#sensor_name = 'Sentinel 2A'\n",
    "#sensor_name = 'Sentinel 2B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "ERROR: Fortran unmixing cannot be loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/g/data/v10/public/modules/dea/unstable/lib/python3.6/site-packages/fc/fractional_cover.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0munmix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munmiximage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /g/data/v10/public/modules/dea/unstable/lib/python3.6/site-packages/fc/unmix/unmiximage.cpython-36m-x86_64-linux-gnu.so)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-28f381ae3e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatacube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatacube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfractional_cover\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_fractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea/unstable/lib/python3.6/site-packages/fc/fractional_cover.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0munmix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munmiximage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR: Fortran unmixing cannot be loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m DEFAULT_MEASUREMENTS = [{\n",
      "\u001b[0;31mException\u001b[0m: ERROR: Fortran unmixing cannot be loaded."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import datacube\n",
    "from datacube.storage import masking\n",
    "from fc.fractional_cover import compute_fractions\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the fractional covers as viewed by the satellite for the site\n",
    "# Required a site properties object\n",
    "def fractionalCoverSatView(siteProperties):\n",
    "    nTotal = siteProperties['num_points']\n",
    "    # Canopy Layer\n",
    "    nCanopyBranch = siteProperties['over_b'] * nTotal / 100.0\n",
    "    nCanopyDead = siteProperties['over_d'] * nTotal / 100.0\n",
    "    nCanopyGreen = siteProperties['over_g'] * nTotal / 100.0\n",
    "    # Midstory Layer\n",
    "    nMidBranch = siteProperties['mid_b'] * nTotal / 100.0\n",
    "    nMidGreen = siteProperties['mid_g'] * nTotal / 100.0\n",
    "    nMidDead = siteProperties['mid_d'] * nTotal / 100.0\n",
    "    # Ground Layer\n",
    "    nGroundDeadLitter = (siteProperties['dead'] + siteProperties['litter']) * nTotal / 100.0\n",
    "    nGroundCrustDistRock = (siteProperties['crust'] + siteProperties['dist'] + siteProperties['rock']) * nTotal / 100.0\n",
    "    nGroundGreen = siteProperties['green'] * nTotal / 100.0\n",
    "    nGroundCrypto = siteProperties['crypto'] * nTotal / 100.0\n",
    "    # Work out the canopy elements as viewed from above\n",
    "    canopyFoliageProjectiveCover = nCanopyGreen / (nTotal - nCanopyBranch)\n",
    "    canopyDeadProjectiveCover = nCanopyDead / (nTotal - nCanopyBranch)\n",
    "    canopyBranchProjectiveCover = nCanopyBranch / nTotal * (1.0 - canopyFoliageProjectiveCover - canopyDeadProjectiveCover)\n",
    "    canopyPlantProjectiveCover = (nCanopyGreen+nCanopyDead + nCanopyBranch) / nTotal\n",
    "    # Work out the midstorey fractions\n",
    "    midFoliageProjectiveCover = nMidGreen / nTotal\n",
    "    midDeadProjectiveCover = nMidDead / nTotal\n",
    "    midBranchProjectiveCover = nMidBranch / nTotal\n",
    "    midPlantProjectiveCover = (nMidGreen + nMidDead + nMidBranch) / nTotal\n",
    "    # Work out the midstorey  elements as viewed by the satellite using a gap fraction method\n",
    "    satMidFoliageProjectiveCover = midFoliageProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidDeadProjectiveCover = midDeadProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidBranchProjectiveCover = midBranchProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidPlantProjectiveCover = midPlantProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    # Work out the groundcover fractions as seen by the observer\n",
    "    groundPVCover = nGroundGreen / nTotal\n",
    "    groundNPVCover = nGroundDeadLitter / nTotal\n",
    "    groundBareCover = nGroundCrustDistRock / nTotal\n",
    "    groundCryptoCover = nGroundCrypto / nTotal\n",
    "    groundTotalCover = (nGroundGreen + nGroundDeadLitter + nGroundCrustDistRock) / nTotal\n",
    "    # Work out the ground cover propoetions as seen by the satellite\n",
    "    satGroundPVCover = groundPVCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundNPVCover = groundNPVCover * ( 1- midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundBareCover = groundBareCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundCryptoCover = groundCryptoCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundTotalCover = groundTotalCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    # Final total covers calculated using gap probabilities through all layers\n",
    "    totalPVCover = canopyFoliageProjectiveCover + satMidFoliageProjectiveCover + satGroundPVCover\n",
    "    totalNPVCover = canopyDeadProjectiveCover + canopyBranchProjectiveCover + satMidDeadProjectiveCover + satMidBranchProjectiveCover + satGroundNPVCover\n",
    "    totalBareCover = satGroundBareCover\n",
    "    totalCryptoCover = satGroundCryptoCover\n",
    "    \n",
    "    return np.array([totalPVCover,totalNPVCover+totalCryptoCover,totalBareCover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients for FC compute\n",
    "ls8_coefficients_current = {'blue': [0.00041, 0.9747], 'green': [0.00289, 0.99779], 'red': [0.00274, 1.00446], \n",
    "                       'nir': [4e-05, 0.98906], 'swir1': [0.00256, 0.99467], 'swir2': [-0.00327, 1.02551]}\n",
    "\n",
    "ls8_coefficients = {'blue': [0.00041*1e4, 0.9747], 'green': [0.00289*1e4, 0.99779], 'red': [0.00274*1e4, 1.00446], \n",
    "                       'nir': [4e-05*1e4, 0.98906], 'swir1': [0.00256*1e4, 0.99467], 'swir2': [-0.00327*1e4, 1.02551]}\n",
    "\n",
    "s2_coefficients = {'blue':[-0.0022*1e4, 0.9551],\n",
    "                   'green':[0.0031*1e4, 1.0582],\n",
    "                   'red':[0.0064*1e4, 0.9871],\n",
    "                   'nir':[0.012*1e4, 1.0187],\n",
    "                   'swir1':[0.0079*1e4, 0.9528],\n",
    "                   'swir2':[-0.0042*1e4, 0.9688]}\n",
    "\n",
    "# compute FC \n",
    "def compute_fc(input_ds, regression_coefficients):\n",
    "    input_data = input_ds.to_array().data\n",
    "    is_valid_array= (input_data >0).all(axis=0)\n",
    "    # Set nodata to 0                                                       \n",
    "    input_data[:, ~is_valid_array] = 0\n",
    "    # compute fractional_cover\n",
    "    output_data = compute_fractions(input_data, regression_coefficients)\n",
    "    output_data[:, ~is_valid_array] = -1\n",
    "    return xr.DataArray(output_data, dims=('band','y','x'),\n",
    "                        coords={'x':input_ds.x, 'y':input_ds.y, 'band':['PV', 'NPV', 'BS', 'UE']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select good pixels using pixel quality\n",
    "def ls_good(pq):\n",
    "    return masking.make_mask(pq, cloud_acca = \"no_cloud\", cloud_fmask = \"no_cloud\",\n",
    "                             cloud_shadow_acca = \"no_cloud_shadow\",\n",
    "                             cloud_shadow_fmask = \"no_cloud_shadow\",\n",
    "                             contiguous = True)\n",
    "def s2_good(pq):\n",
    "    return pq == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral bands used for fractional cover calculation\n",
    "ls_bands = ['green','red','nir','swir1','swir2']\n",
    "s2_bands = ['nbart_green','nbart_red','nbart_nir_1','nbart_swir_2','nbart_swir_3']\n",
    "\n",
    "# sensor specific configurations\n",
    "sensor_config = {'Landsat 7':{'startdate':'1999-05-01', 'product':'ls7_nbart_albers', 'bands':ls_bands,\n",
    "                              'resolution':(25,25), 'fc_coefficients': None,\n",
    "                             'pq_product':'ls7_pq_albers', 'pq_band':'pixelquality', 'pq_mask': ls_good}, \n",
    "                 'Landsat 8 noscaling':{'startdate':'2013-03-01', 'product':'ls8_nbart_albers', 'bands':ls_bands,\n",
    "                              'resolution':(25,25), 'fc_coefficients': None,\n",
    "                             'pq_product':'ls8_pq_albers', 'pq_band':'pixelquality', 'pq_mask': ls_good}, \n",
    "                 'Landsat 8':{'startdate':'2013-03-01', 'product':'ls8_nbart_albers', 'bands':ls_bands,\n",
    "                              'resolution':(25,25), 'fc_coefficients':ls8_coefficients,\n",
    "                             'pq_product':'ls8_pq_albers', 'pq_band':'pixelquality', 'pq_mask': ls_good}, \n",
    "                 'Landsat 8 current':{'startdate':'2013-03-01', 'product':'ls8_nbart_albers', 'bands':ls_bands,\n",
    "                              'resolution':(25,25), 'fc_coefficients':ls8_coefficients_current,\n",
    "                             'pq_product':'ls8_pq_albers', 'pq_band':'pixelquality', 'pq_mask': ls_good}, \n",
    "                 'Sentinel 2A':{'startdate':'2015-07-01', 'product':'s2a_ard_granule', 'bands':s2_bands,\n",
    "                              'resolution':(10,10), 'fc_coefficients':s2_coefficients,\n",
    "                             'pq_product':'s2a_ard_granule', 'pq_band':'fmask', 'pq_mask': s2_good},\n",
    "                'Sentinel 2B':{'startdate':'2017-06-01', 'product':'s2b_ard_granule', 'bands':s2_bands,\n",
    "                              'resolution':(10,10), 'fc_coefficients':s2_coefficients,\n",
    "                             'pq_product':'s2b_ard_granule', 'pq_band':'fmask', 'pq_mask': s2_good}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load star_transects field data\n",
    "field = pd.read_csv('star_transects.csv')\n",
    "field['geometry'] = field.geom.apply(wkt.loads)\n",
    "field = gpd.GeoDataFrame(field)\n",
    "field.crs = {'init': 'EPSG:4326'}\n",
    "field = field.to_crs({'init':'EPSG:3577'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by date\n",
    "field = field.loc[field['obs_time'] > sensor_config[sensor_name]['startdate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate field measured fractions\n",
    "field = field.merge(\n",
    "    field.apply(fractionalCoverSatView, axis=1, result_type= 'expand').rename(\n",
    "        columns = {0:'total_pv',1:'total_npv',2:'total_bs'}),\n",
    "    left_index=True, right_index=True)\n",
    "field = field[field.apply(lambda x: x['total_pv']+x['total_npv']+x['total_bs'], axis=1) >0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match to albers tiles to check distribution\n",
    "albers_tiles = gpd.read_file('/g/data/u46/users/fxy120/sensor_data_maps/Albers_Australia_Coast_and_Islands.shp')\n",
    "albers_tiles.crs = {'init':'EPSG:3577'}\n",
    "matched = gpd.sjoin(field, albers_tiles, how='inner', op = 'intersects')\n",
    "field_tiles = albers_tiles.merge(matched.groupby('label')['FID'].count().sort_values(ascending=False).to_frame('count').reset_index()\n",
    "    , on='label', how='right')\n",
    "print(\"Total number of data points is\",len(field))\n",
    "print(\"Largest number of data points in a tile is\", field_tiles.loc[field_tiles['count'].idxmax()]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check of field data distribution\n",
    "f, axes = plt.subplots(1, 2, figsize=(14,7))\n",
    "field.plot(markersize=1, ax=axes[0])\n",
    "field_tiles.plot(column='count', cmap = 'viridis', ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from cube\n",
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find temporally and spatially aligned EO data \n",
    "# calculate fractional cover\n",
    "def fractionalCover(row, sensor_config = sensor_config[sensor_name], plot_rad = 50, window_days = 15):\n",
    "    # nodata default\n",
    "    fc_dict = {'fc_time': '', 'pv': -1, 'npv': -1, 'bs': -1, 'pv_std': -1, 'npv_std': -1, 'bs_std': -1 }\n",
    "    # define search\n",
    "    x = row.geometry.x - plot_rad, row.geometry.x + plot_rad\n",
    "    y = row.geometry.y - plot_rad, row.geometry.y + plot_rad\n",
    "    time = (str(np.datetime64(row.obs_time) - np.timedelta64(window_days,'D')),\n",
    "            str(np.datetime64(row.obs_time) + np.timedelta64(window_days,'D'))\n",
    "           )\n",
    "    # search for nbart and require result\n",
    "    nbart = dc.load(product = sensor_config['product'], \n",
    "        measurements = sensor_config['bands'],\n",
    "        group_by = 'solar_day',\n",
    "        x = x, y = y, crs = 'EPSG:3577', time = time, resolution = sensor_config['resolution'], output_crs = 'EPSG:3577'\n",
    "       )\n",
    "    if not nbart: return fc_dict\n",
    "    # search for pixel quality and require result\n",
    "    pq = dc.load(product = sensor_config['pq_product'], \n",
    "        measurements = [sensor_config['pq_band']],\n",
    "        group_by = 'solar_day',\n",
    "        x = x, y = y, crs = 'EPSG:3577', time = time, resolution = sensor_config['resolution'], output_crs = 'EPSG:3577'\n",
    "       )\n",
    "    if not pq: return fc_dict\n",
    "    # filter by pixel quality and require good pixels\n",
    "    good = pq.apply(sensor_config['pq_mask'])[sensor_config['pq_band']]\n",
    "    nbart = nbart.where(good, drop=True).sel(x = slice(x[0],x[1]), y = slice(y[0],y[1]))\n",
    "    if len(nbart.time) == 0: return fc_dict\n",
    "    # require all pixels to be clear\n",
    "    nbart.isel(time = ~nbart.isnull().to_array(dim='band').groupby('time','band').any().values)\n",
    "    if len(nbart.time) == 0: return fc_dict\n",
    "    # only keep closest time\n",
    "    nbart = nbart.isel(time=[np.abs(nbart.time-np.datetime64(row.obs_time)).argmin()])\n",
    "    # compute FC\n",
    "    fc = nbart.groupby('time').apply(compute_fc,\n",
    "                                     regression_coefficients = sensor_config['fc_coefficients'],\n",
    "                                    ).to_dataset(dim='band')\n",
    "    # take average\n",
    "    fc_mean = fc.where(fc>=0).groupby('time').mean()\n",
    "    fc_std = fc.where(fc>=0).groupby('time').std()\n",
    "    \n",
    "    fc_dict['fc_time'] = fc.time.values[0].astype(str)\n",
    "    for var_name in fc_mean.data_vars:\n",
    "        fc_dict[var_name.lower()] = fc_mean[var_name].values[0]\n",
    "        fc_dict[var_name.lower()+'_std'] = fc_std[var_name].values[0]\n",
    "    return fc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find temporally and spatially aligned FC data\n",
    "def get_fractionalCover(row, sensor_config = sensor_config[sensor_name], plot_rad = 50, window_days =15 ):\n",
    "    # nodata default\n",
    "    fc_dict = {'fc_time': '', 'pv': -1, 'npv': -1, 'bs': -1, 'pv_std': -1, 'npv_std': -1, 'bs_std': -1 }\n",
    "    # define search\n",
    "    x = row.geometry.x - plot_rad, row.geometry.x + plot_rad\n",
    "    y = row.geometry.y - plot_rad, row.geometry.y + plot_rad\n",
    "    time = (str(np.datetime64(row.obs_time) - np.timedelta64(window_days,'D')),\n",
    "            str(np.datetime64(row.obs_time) + np.timedelta64(window_days,'D'))\n",
    "           )\n",
    "    # search for nbart and require result\n",
    "    fc = dc.load(product = sensor_config['product'].replace('nbart','fc'), \n",
    "        #measurements = sensor_config['bands'],\n",
    "        group_by = 'solar_day',\n",
    "        x = x, y = y, crs = 'EPSG:3577', time = time, resolution = sensor_config['resolution'], output_crs = 'EPSG:3577'\n",
    "       )\n",
    "    if not fc: return fc_dict\n",
    "    # search for pixel quality and require result\n",
    "    pq = dc.load(product = sensor_config['pq_product'], \n",
    "        measurements = [sensor_config['pq_band']],\n",
    "        group_by = 'solar_day',\n",
    "        x = x, y = y, crs = 'EPSG:3577', time = time, resolution = sensor_config['resolution'], output_crs = 'EPSG:3577'\n",
    "       )\n",
    "    if not pq: return fc_dict\n",
    "    # filter by pixel quality and require good pixels\n",
    "    good = pq.apply(sensor_config['pq_mask'])[sensor_config['pq_band']]\n",
    "    fc = fc.where(good, drop=True).sel(x = slice(x[0],x[1]), y = slice(y[0],y[1]))\n",
    "    if len(fc.time) == 0: return fc_dict\n",
    "    # require all pixels to be clear\n",
    "    fc.isel(time = ~fc.isnull().to_array(dim='band').groupby('time','band').any().values)\n",
    "    if len(fc.time) == 0: return fc_dict\n",
    "    # only keep closest time\n",
    "    fc = fc.isel(time=[np.abs(fc.time-np.datetime64(row.obs_time)).argmin()])\n",
    "    # take average\n",
    "    fc_mean = fc.where(fc>=0).groupby('time').mean()\n",
    "    fc_std = fc.where(fc>=0).groupby('time').std()\n",
    "    \n",
    "    fc_dict['fc_time'] = fc.time.values[0].astype(str)\n",
    "    for var_name in fc_mean.data_vars:\n",
    "        fc_dict[var_name.lower()] = fc_mean[var_name].values[0]\n",
    "        fc_dict[var_name.lower()+'_std'] = fc_std[var_name].values[0]\n",
    "    return fc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fractions = field.apply(fractionalCover, axis=1, result_type = 'expand')\n",
    "field = field.merge(fractions, how = 'inner', left_index=True, right_index=True)\n",
    "field = field[field['pv']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.to_file('field_with_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = gpd.read_file('field_with_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "def validate(field_all, title=None):\n",
    "    field = field_all[(field_all[['pv','npv','bs']]>=0.).all(axis=1)]\n",
    "    field = field[(field[['pv_std','npv_std','bs_std']]<=10.).all(axis=1)]\n",
    "    field = field[field['ue'] <25]\n",
    "    print(\"# of validation points:\", len(field))\n",
    "    \n",
    "    regr = linear_model.LinearRegression(fit_intercept=False)    \n",
    "\n",
    "    f = plt.figure(figsize=(12,12))\n",
    "    gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "    xedges=yedges=list(np.arange(0,102,2))\n",
    "    X, Y = np.meshgrid(xedges, yedges)\n",
    "    cmname='YlGnBu'\n",
    "    if title: plt.suptitle(title)\n",
    "    \n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    field.plot(markersize=1, ax= ax1, color='r')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_title('Field Sites')\n",
    "    ax1.text(0.05, 0.05, \"%d points\"%len(field), transform=ax1.transAxes)\n",
    "    \n",
    "    rmses = []\n",
    "    for band_id, band in enumerate(['BS','PV','NPV']):\n",
    "        arr1 = field['total_%s'%band.lower()].values.ravel()*100.\n",
    "        arr2 = field[band.lower()].values.ravel()\n",
    "        regr.fit(arr1[:,np.newaxis], arr2[:,np.newaxis])\n",
    "        \n",
    "        print('Band:{0}, slope={1}, r2={2}'.format(band, regr.coef_[0][0],\n",
    "                                                regr.score(arr1[:,np.newaxis], arr2[:,np.newaxis])))\n",
    "        sr = spearmanr(arr1, arr2)[0]\n",
    "        print('Correlations:', pearsonr(arr1, arr2)[0], sr, kendalltau(arr1, arr2)[0])\n",
    "        rmse = np.sqrt(mean_squared_error(arr1, arr2))\n",
    "        print('RMSE:',rmse)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "        ax1 = plt.subplot(gs[band_id+1])\n",
    "        ax1.scatter(arr1, arr2, s=3)\n",
    "        ax1.set_title(band)\n",
    "        \n",
    "        ax1.plot([0,100],[0,100])\n",
    "        ax1.plot(np.arange(0,100,10), regr.predict(np.arange(0,100,10)[:,np.newaxis]), ':')\n",
    "        ax1.text(5, 95, 'spearmanr = {0:.2f}'.format(sr))\n",
    "        ax1.text(5, 90, 'rmse = {0:.2f}'.format(rmse))\n",
    "        ax1.set_xlabel('Field Measured')\n",
    "        ax1.set_ylabel('%s FC'%sensor_name.upper())\n",
    "        ax1.set_xlim((0,100))\n",
    "        ax1.set_ylim((0,100))\n",
    "    \n",
    "    f.savefig('validate_fc_%s.png'%''.join(sensor_name.split()))\n",
    "\n",
    "\n",
    "validate(field, title=sensor_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
