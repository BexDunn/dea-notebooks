{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Imagery for ARI Manual Classification Workflow <img align=\"right\" src=\"../../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule),\n",
    "[ga_ls5t_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The ability to extract pixel boundaries as a shapefile or other vector file type is very useful for remote sensing applications where the boundaries of the pixel are needed. \n",
    "This is useful for matching drone imagery with remotely sensed imagery. The Fractional Cover of Water project requires us to use satellite imagery from Landsat and Sentinel 2 satellites that match our drone imagery from our field sites. We take the matching imagery, find the pixel edges, and then manually classify what is in the pixels (what type of wet vegetation we have and what fraction of the pixel it covers), in order to create input data for the algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook uses Digital Earth Australia to retrieve satellite data, creates a vector file from the pixel boundaries of the data, and exports to file.\n",
    "\n",
    "#FIXME: first bring in the drone data\n",
    "\n",
    "\n",
    "1. First we load some data for a chosen time frame and area using the dea-notebooks `load_ard` function\n",
    "2. Then we convert our raster data into a polygon per pixel\n",
    "3. Then we export our pixel edges polygons as a vector file (e.g. ESRI Shapefile or GeoJSON)\n",
    "4. This loop is repeated (once for Sentinel-2 data and once for Landsat data)\n",
    "\n",
    "#FIXME: additional steps\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import datacube\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "import xarray as xr\n",
    "\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "from datacube.utils.geometry import GeoBox\n",
    "from odc.algo import xr_reproject\n",
    "\n",
    "sys.path.append(\"../../../Scripts\") #update this before push?\n",
    "from dea_datahandling import load_ard\n",
    "from dea_plotting import rgb\n",
    "import dea_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dea_dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35113 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33855</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/bex/proxy/35113/status' target='_blank'>/user/bex/proxy/35113/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>61.42 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33855' processes=1 threads=8, memory=61.42 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful functions\n",
    "The function below is a helper function to help you make a nice filename for the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filename(ds, image_index, query, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Create_filename is a handy function to turn your xarray.Dataset \n",
    "    and image number into a nice output filename for your shapefile.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray.Dataset\n",
    "        Input xarray.Dataset data\n",
    "    image_index : int\n",
    "        An integer value between 0 and however many images you have\n",
    "    prefix : string, optional \n",
    "        An optional name prefix to identify your area of interest\n",
    "        \"\"\"\n",
    "    assert ds\n",
    "    \n",
    "    image_date = str(ds.nbart_red[image_index].time.data)[:10]\n",
    "    image_coords = f\"{query['x'][0]}_{query['y'][0]}_{query['x'][1]}_{query['y'][1]}\"\n",
    "    \n",
    "    if prefix:\n",
    "        output_name = f\"{str(prefix)}_{image_date}_{image_coords}\"\n",
    "    else:\n",
    "        output_name = f\"{image_date}_{image_coords}\"\n",
    "        print(output_name)\n",
    "        \n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Manual classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the drone orthomosaic for your wetland of interest\n",
    "The path here points to the example_data folder; change if necessary.\n",
    "You need to have the data exported from DroneDeploy in Web Mercator projection, `epsg:3857`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_tif_path = 'example_data/Sbends_Orthomosaic_export_TueAug18040306687120.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import drone data using xr.open_rasterio and datacube.utils.geometry.assign_crs to get the crs in a datacube-friendly modality\n",
    "drone = assign_crs(xr.open_rasterio(drone_tif_path, parse_coordinates=True, chunks={'band': 1, 'x': 1024, 'y': 1024}))\n",
    "#Create a box around our imported data, in order to load and compare the same data\n",
    "drone_geobox = GeoBox.from_geopolygon(drone.geobox.extent, drone.geobox.resolution  , 'epsg:3577')\n",
    "#Now reproject our original drone imagery to Australian Albers Equal Area, CRS epsg:3577 in order to compare our imagery correctly with the pixels from our satellite imagery\n",
    "drone = xr_reproject(drone, drone_geobox, resampling= 'bilinear' )\n",
    "#Convert the DataArray to a Dataset so we can investigate the data as variables in an xarray, making it easier for us to plot them nicely. \n",
    "drone_ds = drone.to_dataset(dim ='band',)\n",
    "#rename our bands according to their colors\n",
    "drone_ds = drone_ds.rename(name_dict = {1:'drone_red', 2:'drone_green', 3:'drone_blue', 4:'drone_alpha'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(drone_ds, bands=['drone_red','drone_green','drone_blue'], size =20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-2 example \n",
    "### Set up a datacube query for area of interest\n",
    "Set up a query to load Sentinel-2 satellite data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query object\n",
    "s2_query = {\n",
    "    \"x\": (153.44, 153.45),\n",
    "    \"y\": (-27.42, -27.43),\n",
    "    \"time\": (\"2018-08-01\", \"2018-08-20\"),\n",
    "    \"products\": (\"s2a_ard_granule\", \"s2b_ard_granule\"),\n",
    "    \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"fmask\"],\n",
    "    \"output_crs\": \"EPSG:3577\",\n",
    "    \"resolution\": (-10, 10),\n",
    "    \"group_by\": \"solar_day\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load available data from Sentinel 2 satellites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 data using `load_ard`. We're not using fmask to mask our \n",
    "# pixel quality, as we're after the surrounds of the pixels not big white blobs.\n",
    "s2_ds = load_ard(\n",
    "    dc=dc,\n",
    "    min_gooddata=0.95,  # only take scenes with less than 5% fmask activations\n",
    "    mask_pixel_quality=False,\n",
    "    **s2_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up some data to take a look at it\n",
    "Use the `rgb` function from `dea-plotting` module to look at our area of interest in true colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(s2_ds, bands=[\"nbart_red\", \"nbart_green\", \"nbart_blue\"], col=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an image index to use to polygonise the pixels\n",
    "Change the number in the cell below to select a different image from the images in the previous cell; 0 is the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment our image into per-pixel-polygons\n",
    "Use the red band to create a polygon for each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input array to segment and vectorise\n",
    "input_array = s2_ds.nbart_red[image_index]\n",
    "input_transform = s2_ds.affine  \n",
    "input_crs = s2_ds.crs\n",
    "\n",
    "# Create array with a unique value per cell\n",
    "unique_pixels = np.arange(input_array.size).reshape(input_array.shape)\n",
    "\n",
    "# Vectorise each unique feature in array\n",
    "vectors = rasterio.features.shapes(\n",
    "    source=unique_pixels.astype(np.int16), transform=input_transform\n",
    ")\n",
    "\n",
    "# Extract polygons and values from generator\n",
    "vectors = list(vectors)\n",
    "values = [value for polygon, value in vectors]\n",
    "polygons = [shape(polygon) for polygon, value in vectors]\n",
    "\n",
    "s2_poly_gdf=gpd.GeoDataFrame(data={\"id\": values}, geometry=polygons, crs=input_crs)\n",
    "\n",
    "#add in some empty fields for our classification here. \n",
    "info_fields = [\"Overstory\",\"Emergent\",\"Floating\",\"OpenWater\",\"GreenVeg\",\"DryVeg\",\"Bare\",\"ForelUleWaterColour\"]\n",
    "for i in info_fields:\n",
    "    s2_poly_gdf[i]=np.nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the results\n",
    "Print and plot the first 5 entries in the polygon GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows in the GeoDataFrame\n",
    "s2_poly_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot shapefile over raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raster data\n",
    "fig, ax1 = plt.subplots(figsize=[8, 8])\n",
    "rgb(\n",
    "    s2_ds.isel(time=image_index),\n",
    "    bands=[\"nbart_red\", \"nbart_green\", \"nbart_blue\"],\n",
    "    ax=ax1,\n",
    ")\n",
    "\n",
    "# Plot our shapefile over top of our raster\n",
    "s2_poly_gdf.boundary.plot(color=None, edgecolor=\"k\", linewidth=0.2, ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write polygonised pixel edges to file\n",
    "Change the prefix in the cell below for a customised filename, and write our new segmented shapefile out to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = create_filename(s2_ds, image_index, s2_query, prefix=\"NS_s2\")\n",
    "s2_poly_gdf.to_file(f\"{output_filename}.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write corresponding RGB GeoTIFF image data to file\n",
    "Write the corresponding GeoTIFF out to a file, for checking purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_rgb = s2_ds.isel(time=image_index).to_array()\n",
    "write_cog(s2_rgb, f\"{output_filename}.tif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landsat example \n",
    "\n",
    "### Set up a datacube query for area of interest\n",
    "Set up a query to reproduce our workflow using Landsat satellite data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a landsat query\n",
    "ls_query = {\n",
    "    \"x\": (153.44, 153.45),\n",
    "    \"y\": (-27.42, -27.43),\n",
    "    \"time\": (\"2018-08-01\", \"2018-08-20\"),\n",
    "    \"products\": [\"ga_ls5t_ard_3\", \"ga_ls7e_ard_3\", \"ga_ls8c_ard_3\"],\n",
    "    \"measurements\": [\n",
    "        \"nbart_green\",\n",
    "        \"nbart_red\",\n",
    "        \"nbart_blue\",\n",
    "    ],  # only get the bands we need for plotting and segmenting\n",
    "    \"output_crs\": \"EPSG:3577\",\n",
    "    \"resolution\": (-30, 30),\n",
    "    \"group_by\": \"solar_day\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load available data from Landsat satellites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load landsat data using `load_ard`\n",
    "ls_ds = load_ard(dc=dc, ls7_slc_off=False, **ls_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "Use the `rgb` function from `dea_plotting` module to look at our area of interest in true colour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ls_ds, bands=[\"nbart_red\", \"nbart_green\", \"nbart_blue\"], col=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment image into per-pixel-polygons\n",
    "Use the red band to create a polygon for each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input array to segment and vectorise\n",
    "input_array = ls_ds.nbart_red[image_index]\n",
    "input_transform = ls_ds.affine\n",
    "input_crs = ls_ds.crs\n",
    "\n",
    "# Create array with a unique value per cell\n",
    "unique_pixels = np.arange(input_array.size).reshape(input_array.shape)\n",
    "\n",
    "# Vectorise each unique feature in array\n",
    "vectors = rasterio.features.shapes(\n",
    "    source=unique_pixels.astype(np.int16), transform=input_transform\n",
    ")\n",
    "\n",
    "# Extract polygons and values from generator\n",
    "vectors = list(vectors)\n",
    "values = [value for polygon, value in vectors]\n",
    "polygons = [shape(polygon) for polygon, value in vectors]\n",
    "\n",
    "# Create a geopandas dataframe populated with the polygon shapes\n",
    "ls_poly_gdf = gpd.GeoDataFrame(data={\"id\": values}, geometry=polygons, crs=input_crs)\n",
    "\n",
    "#add in some empty fields for our classification here. \n",
    "for i in info_fields:\n",
    "    ls_poly_gdf[i]=np.nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the results\n",
    "Print and plot the first 5 entries in the polygon GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows in the GeoDataFrame\n",
    "ls_poly_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot shapefile over raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raster data\n",
    "fig, ax1 = plt.subplots(figsize=[8,8])\n",
    "rgb(ls_ds.isel(time=image_index), bands=[\"nbart_red\", \"nbart_green\", \"nbart_blue\"], ax=ax1)\n",
    "\n",
    "# Plot our shapefile over top of our raster\n",
    "ls_poly_gdf.boundary.plot(color=None, edgecolor='k', linewidth = 0.2, ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write polygonised pixel edges out to file\n",
    "Write our new segmented Landsat pixel edge shapefile out to a file (change the prefix in the cell below for a customised filename):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = create_filename(ls_ds, image_index, ls_query, prefix=\"NS_ls\")\n",
    "ls_poly_gdf.to_file(f\"{output_filename}.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write corresponding RGB GeoTIFF image data to file\n",
    "Write the corresponding geotiff out to a file, for checking purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_rgb = ls_ds.isel(time=image_index).to_array()\n",
    "write_cog(ls_rgb, f\"{output_filename}.tif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** August 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`,:index:`landsat 5`, :index:`landsat 7`, :index:`landsat 8`, :index:`sentinel 2`, :index:`dea_datahandling`, :index:`dea_plotting`, :index:`rgb`, :index:`load_ard`, :index:`vectorise`, :index:`shapefile`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
