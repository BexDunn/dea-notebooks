{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T21:48:09.619004Z",
     "start_time": "2019-02-20T21:48:09.566498Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import write_geotiff\n",
    "from datacube import Datacube\n",
    "from datetime import datetime\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "\n",
    "import datacube\n",
    "import datetime\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "from shapely import geometry\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "###FIXME: this is for getting s2 to write to geotiff\n",
    "import rasterio\n",
    "\n",
    "# Point this to where you have the algorithms from the dea-notebooks/algorithms saved\n",
    "sys.path.append('../../10_Scripts')\n",
    "import DEADataHandling, DEAPlotting, TasseledCapTools\n",
    "\n",
    "dc = Datacube(app='Sentinel2')\n",
    "\n",
    "#change the path here if you want a different polygon\n",
    "poly_path = '/g/data/r78/rjd547/shapefiles/EnvironmentalFlowMonitoringPolygon.shp'\n",
    "#poly_path = '/g/data/r78/rjd547/shapefiles/FarmScaleWaterBalancePolygon.shp'\n",
    "\n",
    "#open the polygon\n",
    "with fiona.open(poly_path) as shapes:\n",
    "        crs = geometry.CRS(shapes.crs_wkt)\n",
    "        first_geometry = next(iter(shapes))['geometry']\n",
    "        geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "\n",
    "shape_file = poly_path\n",
    "GEOM, SHAPE_NAME = DEADataHandling.open_polygon_from_shapefile(shape_file)\n",
    "start_of_epoch, end_of_epoch=('2018-05-01', '2018-07-31')\n",
    "\n",
    "query = {\n",
    "    'time': (start_of_epoch, end_of_epoch), \n",
    "    'geopolygon': GEOM,\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "\n",
    "#load in data\n",
    "s2= dc.load(product='s2a_ard_granule', group_by='solar_day', \n",
    "                   measurements=['fmask', \n",
    "                             'nbart_blue', \n",
    "                             'nbart_green', \n",
    "                             'nbart_red', \n",
    "                             'nbart_red_edge_1',\n",
    "                             'nbart_red_edge_2',\n",
    "                             'nbart_red_edge_3',\n",
    "                             'nbart_nir_1',\n",
    "                             'nbart_nir_2',\n",
    "                             'nbart_swir_2',\n",
    "                             'nbart_swir_3'], **query)\n",
    "#### See what came back from the extraction\n",
    "\n",
    "s2\n",
    "\n",
    "ds=s2\n",
    "\n",
    "#get polygon name from the polygon path\n",
    "polyname = poly_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "savefilepath = '/g/data/r78/rjd547/WaterCompHackFeb2019/Sentinel2Data/'+polyname\n",
    "\n",
    "filename=savefilepath\n",
    "\n",
    "#### this is a really annoying kludge to deal with the fact that new sentinel data has multiple data types and the functions were not written to cope\n",
    "\n",
    "ds\n",
    "\n",
    "## Sneakily force fmask layer to int16 type\n",
    "\n",
    "ds['fmask']=ds['fmask'].astype(np.int16)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T21:48:09.619004Z",
     "start_time": "2019-02-20T21:48:09.566498Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import write_geotiff\n",
    "from datacube import Datacube\n",
    "from datetime import datetime\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "\n",
    "import datacube\n",
    "import datetime\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "from shapely import geometry\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "###FIXME: this is for getting s2 to write to geotiff\n",
    "import rasterio\n",
    "\n",
    "# Point this to where you have the algorithms from the dea-notebooks/algorithms saved\n",
    "sys.path.append('../../10_Scripts')\n",
    "import DEADataHandling, DEAPlotting, TasseledCapTools\n",
    "\n",
    "dc = Datacube(app='Sentinel2')\n",
    "\n",
    "#change the path here if you want a different polygon\n",
    "poly_path = '/g/data/r78/rjd547/shapefiles/EnvironmentalFlowMonitoringPolygon.shp'\n",
    "#poly_path = '/g/data/r78/rjd547/shapefiles/FarmScaleWaterBalancePolygon.shp'\n",
    "\n",
    "#open the polygon\n",
    "with fiona.open(poly_path) as shapes:\n",
    "        crs = geometry.CRS(shapes.crs_wkt)\n",
    "        first_geometry = next(iter(shapes))['geometry']\n",
    "        geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "\n",
    "shape_file = poly_path\n",
    "GEOM, SHAPE_NAME = DEADataHandling.open_polygon_from_shapefile(shape_file)\n",
    "start_of_epoch, end_of_epoch=('2018-05-01', '2018-07-31')\n",
    "\n",
    "query = {\n",
    "    'time': (start_of_epoch, end_of_epoch), \n",
    "    'geopolygon': GEOM,\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "#load in data\n",
    "s2= dc.load(product='s2b_ard_granule', group_by='solar_day', \n",
    "                   measurements=['fmask', \n",
    "                             'nbart_blue', \n",
    "                             'nbart_green', \n",
    "                             'nbart_red', \n",
    "                             'nbart_red_edge_1',\n",
    "                             'nbart_red_edge_2',\n",
    "                             'nbart_red_edge_3',\n",
    "                             'nbart_nir_1',\n",
    "                             'nbart_nir_2',\n",
    "                             'nbart_swir_2',\n",
    "                             'nbart_swir_3'], **query)\n",
    "#### See what came back from the extraction\n",
    "s2\n",
    "ds=s2\n",
    "#get polygon name from the polygon path\n",
    "polyname = poly_path.split('/')[-1].split('.')[0]\n",
    "savefilepath = '/g/data/r78/rjd547/WaterCompHackFeb2019/Sentinel2Data/'+polyname\n",
    "filename=savefilepath\n",
    "#### this is a really annoying kludge to deal with the fact that new sentinel data has multiple data types and the functions were not written to cope\n",
    "ds\n",
    "## Sneakily force fmask layer to int16 type\n",
    "ds['fmask']=ds['fmask'].astype(np.int16)\n",
    "ds\n",
    "###Note: I munged this to change the datatype for S2\n",
    "def dataset_to_geotiff2(filename, data):\n",
    "    # Depreciation warning for write_geotiff\n",
    "    print(\"This function will be superceded by the 'write_geotiff' function from 'datacube.helpers'. \"\n",
    "          \"Please revise your notebooks to use this function instead\")\n",
    "    kwargs = {'driver': 'GTiff',\n",
    "              'count': len(data.data_vars),  # geomedian no time dim\n",
    "              'width': data.sizes['x'], 'height': data.sizes['y'],\n",
    "              'crs': data.crs.crs_str,\n",
    "              'transform': data.affine,\n",
    "              'dtype': list(data.data_vars.values())[0].values.dtype,\n",
    "              'nodata': 0,\n",
    "              'compress': 'deflate', 'zlevel': 4, 'predictor': 2}\n",
    "    # for ints use 2 for floats use 3}\n",
    "    with rasterio.open(filename, 'w', **kwargs) as src:\n",
    "        for i, band in enumerate(data.data_vars):\n",
    "            src.write(data[band].data, i + 1)\n",
    "### write the list of bands to a textfile\n",
    "band_list =[]\n",
    "with open(filename+'band_list_s2.txt','w') as outfile: \n",
    "    for i, band in enumerate(ds.data_vars):\n",
    "        #print(str(f'{i+1} {band} \\n'))\n",
    "        outfile.write(str(f'{i+1} {band} \\n'))\n",
    "        #band_list.append([i+1,band])\n",
    "    #print(band_list)    \n",
    "### Write each date to a separate geotiff\n",
    "print(filename)\n",
    "#print the dates for which we have imagery and write to file\n",
    "for i in range(len(ds.time)):\n",
    "    date_s2 = str(ds.isel(time=i).time.data)[:-19]\n",
    "    filename2='{}s2b_{}.tif'.format(filename,date_s2)\n",
    "    print(date_s2)\n",
    "    dataset_to_geotiff2(filename2, ds.isel(time=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the dates for which we have imagery and write to file\n",
    "for i in range(len(ds.time)):\n",
    "    date_s2 = str(ds.isel(time=i).time.data)[:-19]\n",
    "    filename2='{}_s2b_{}.tif'.format(filename,date_s2)\n",
    "    print(date_s2)\n",
    "    #dataset_to_geotiff2(filename2, ds.isel(time=i))\n",
    "    # Depreciation warning for write_geotiff\n",
    "    print(\"This function will be superceded by the 'write_geotiff' function from 'datacube.helpers'. \"\n",
    "          \"Please revise your notebooks to use this function instead\")\n",
    "    data = ds.isel(time=i)\n",
    "    kwargs = {'driver': 'GTiff',\n",
    "              'count': len(data.data_vars),  # geomedian no time dim\n",
    "              'width': data.sizes['x'], 'height': data.sizes['y'],\n",
    "              'crs': data.crs.crs_str,\n",
    "              'transform': data.affine,\n",
    "              'dtype': list(data.data_vars.values())[0].values.dtype,\n",
    "              'nodata': 0,\n",
    "              'compress': 'deflate', 'zlevel': 4, 'predictor': 2}\n",
    "    # for ints use 2 for floats use 3}\n",
    "    with rasterio.open(filename2, 'w', **kwargs) as src:\n",
    "        for i, band in enumerate(data.data_vars):\n",
    "            src.write(data[band].data, i + 1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
