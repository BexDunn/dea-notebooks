{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General advice (delete this cell before submitting for review)\n",
    "\n",
    "> * When writing in Markdown cells, start each sentence on a **new line**.\n",
    "This makes it easy to see changes through git commits.\n",
    "> * Check the [known issues](https://github.com/GeoscienceAustralia/dea-docs/wiki/Known-issues) for formatting regarding the conversion of notebooks to DEA docs using Sphinx.\n",
    "Things to be aware of:\n",
    "    * Sphinx is highly sensitive to bulleted lists:\n",
    "        * Ensure that there is an empty line between any preceding text and the list\n",
    "        * Only use the `*` bullet (`-` is not recognised)\n",
    "        * Sublists must be indented by 4 spaces\n",
    "    * Headers must appear in heirachical order (`#`, `##`, `###`, `####`) and there can only be one title (`#`).\n",
    "> * Use the [PEP8 standard](https://www.python.org/dev/peps/pep-0008/) for code. To make sure all code in the notebook is consistent, you can use the `jupyterlab_code_formatter` tool: select each code cell, then click `Edit` and then one of the `Apply X Formatter` options (`YAPF` or `Black` are recommended). This will reformat the code in the cell to a consistent style.\n",
    "\n",
    "> * In the final notebook cell, include a set of relevant tags which are used to build the DEA User Guide's [Tag Index](https://docs.dea.ga.gov.au/genindex.html). \n",
    "\n",
    "Use all lower-case (unless the tag is an acronym), separate words with spaces (unless it is the name of an imported module), and [re-use existing tags](https://github.com/GeoscienceAustralia/dea-notebooks/wiki/List-of-tags).\n",
    "Ensure the tags cell below is in `Raw` format, rather than `Markdown` or `Code`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial display for Wetlands Insight Tool results <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatibility:** Notebook currently compatible with only the `NCI VDI` environment\n",
    "* **Products used:** \n",
    "\n",
    "    * Collection 2 Landsat Surface Reflectance: \n",
    "    [ls5_nbart_albers](https://explorer.dea.ga.gov.au/ls5_nbart_albers),\n",
    "    [ls7_nbart_albers](https://explorer.dea.ga.gov.au/ls7_nbart_albers),\n",
    "    [ls8_nbart_albers](https://explorer.dea.ga.gov.au/ls8_nbart_albers)\n",
    "    \n",
    "    * Collection 2 Landsat Fractional Cover, \n",
    "    generated using the Joint Remote Sensing Research Program algorithm: \n",
    "    [ls5_fc_albers](https://explorer.dea.ga.gov.au/ls5_fc_albers),\n",
    "    [ls7_fc_albers](https://explorer.dea.ga.gov.au/ls7_fc_albers),\n",
    "    [ls8_fc_albers](https://explorer.dea.ga.gov.au/ls8_fc_albers)\n",
    "    \n",
    "    * Water Observations from Space, \n",
    "    generated using the Geoscience Australia Algorithm:\n",
    "    [wofs_albers](https://explorer.sandbox.dea.ga.gov.au/wofs_albers)\n",
    "\n",
    "\n",
    "* **Special requirements:** \n",
    "    * If running on the [NCI](https://nci.org.au/), ensure that `module load dea` is run         prior to launching this notebook\n",
    "    * Check you have the latest version of the `wit_tooling package` by \n",
    "      copying and pasting the following code into a cell below and running the cell\n",
    "\n",
    "    `!pip install --user git+git://github.com/GeoscienceAustralia/wit_tooling`\n",
    "    * You need to paste the database credentials provided into the first code cell \n",
    "      (after packages are loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The Spatial Wetlands Insight Tool is a tool in development to display the coverage of water, \"wetness\" and vegetation in a wetland spatially. It is generated off existing Wetlands Insight Tool temporal runs. \n",
    "\n",
    "Limitations include:\n",
    "\n",
    "This notebook \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook uses an existing Wetlands Insight Tool temporal plot, \n",
    "generated from an existing WIT run, to create a spatial plot of water, \"wetness\", green/photosynthetic vegetation, dry/non-photosynthetic vegetation, and bare soil for a chosen observation date. \n",
    "\n",
    "1. First we load the existing WIT data from a saved csv location, use a shapefile to retrieve the existing WIT data from the database of previous runs, \n",
    "2. Then we choose a time of interest to plot Spatial WIT\n",
    "3. Finally we output Spatial WIT to a file for each cover type\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements - A checklist to remind us if we tick all the boxes\n",
    "---------------------\n",
    "- [ ] Make a nice plot to select a time/ period of interest\n",
    "- [ ] Run WIT on a per-pixel basis\n",
    "- [ ] Return Water/Wet/FC percentage per pixel\n",
    "- [ ] Plot and output WIT spatially, with FC percentage represented as an alpha % for the colour\n",
    "- [ ] Output the results as a ArcGIS-compliant Geotiff (uint8), with the shapefile name and the date in the filename\n",
    "***\n",
    "\n",
    "Functions or functionalities\n",
    "---------\n",
    "`bokeh wit plot`: \n",
    "\n",
    "to do a stack plot of wit data with bokeh\n",
    "\n",
    "input: DataFrame\n",
    "\n",
    "output: stack plot of wit data\n",
    "\n",
    "`load_wit_data(**kwargs)`\n",
    "\n",
    "input: csv file or poly_id in database\n",
    "\n",
    "output: DataFrame\n",
    "\n",
    "`load_wofs_fc(query)`\n",
    "\n",
    "input: a query dictionary with time and geometry\n",
    "\n",
    "output: an xarray with water/wet/FC percentage\n",
    "\n",
    "`plot_spatial_wit(input_pixels_array)`\n",
    "\n",
    "input: an xarray with water/wet/FC percentage\n",
    "\n",
    "output: 2 dimensional plot of input\n",
    "\n",
    "`write_geotiff(input_pixels_array, file_name)`\n",
    "input: an xarray with water/wet/FC percentage\n",
    "\n",
    "a string as file name\n",
    "\n",
    "output: a geotiff file with input file name\n",
    "    ***\n",
    "    \n",
    "Coding/writing style requirements\n",
    "-------------------------\n",
    "- Always break up a sentence if it's too long, slide showing up is a good indicator\n",
    "- Merge all the cells without essential output unless requied not so, e.g, explanation proceeding a functionality\n",
    "- Use `_LOG.debug` provided insted of `print`\n",
    "- Follow the comments in cells to fill in code rather than randomly dump\n",
    "- Keep all the variables humanly readable, a, b, c or aa, bb, cc etc. simple letters or their permutation are forbidden to be used globally\n",
    "Does the front end plumbing that you're designing for WIT spatial encompass multiple potential sources of WIT?\n",
    "- Retrieve data from DB\n",
    "- User uploads WIT CSV file (ie if WA wanted to upload one of the WITs we've just shipped them)\n",
    "- Retrieve pre-calculated WIT from S3 bucket\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook:\n",
    "-----------------------------\n",
    "* Follow the instructions under `Special Requirements` above to load `dea`, `wit_tooling`, and connect to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary packages in this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import fiona\n",
    "import yaml\n",
    "from datacube import Datacube\n",
    "from datacube.utils.cog import write_cog\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook, show, push_notebook\n",
    "from bokeh.layouts import layout, column, row, WidgetBox, gridplot\n",
    "from bokeh.models import (CheckboxGroup, Select,  CategoricalColorMapper, ColumnDataSource,HoverTool, Label,\n",
    "                          SingleIntervalTicker, Slider, DatetimeTickFormatter, YearsTicker, Legend, TapTool,\n",
    "                          CustomJS, LegendItem, field, Range1d)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.models.tickers import DatetimeTicker\n",
    "from bokeh.models import LinearColorMapper\n",
    "from bokeh.colors import RGB\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "from datacube.virtual.impl import VirtualDatasetBox\n",
    "from datacube.virtual import construct\n",
    "from datacube.utils.geometry import CRS, Geometry\n",
    "from shapely.geometry import mapping, box\n",
    "from enum import Enum\n",
    "import os, sys, urllib, logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "from wit_tooling import query_wit_data, load_timeslice, convert_shape_to_polygon, generate_raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy database credentials into the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use database credentials to access wit database\n",
    "os.environ['WIT_DB_HOSTNAME'] = 'wit-test-emma.cxhoeczwhtar.ap-southeast-2.rds.amazonaws.com'\n",
    "os.environ['DB_USERNAME'] = 'dbreader'\n",
    "os.environ['DB_PASSWORD'] = '993ffd204851bcb700e62a65eac8c48e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.2.min.js\": \"ufR9RFnRs6lniiaFvtJziE0YeidtAgBRH6ux2oUItHw5WTvE1zuk9uzhUU/FJXDp\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.2.min.js\": \"8QM/PGWBT+IssZuRcDcjzwIh1mkOmJSoNMmyYDZbCfXJg3Ap1lEvdVgFuSAwhb/J\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.2.min.js\": \"Jm8cH3Rg0P6UeZhVY5cLy1WzKajUT9KImCY+76hEqrcJt59/d8GPvFHjCkYgnSIn\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.2.min.js\": \"Ozhzj+SI7ywm74aOI/UajcWz+C0NjsPunEVyVIrxzYkB+jA+2tUw8x5xJCbVtK5I\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.2.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.2.min.js\": \"ufR9RFnRs6lniiaFvtJziE0YeidtAgBRH6ux2oUItHw5WTvE1zuk9uzhUU/FJXDp\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.2.min.js\": \"8QM/PGWBT+IssZuRcDcjzwIh1mkOmJSoNMmyYDZbCfXJg3Ap1lEvdVgFuSAwhb/J\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.2.min.js\": \"Jm8cH3Rg0P6UeZhVY5cLy1WzKajUT9KImCY+76hEqrcJt59/d8GPvFHjCkYgnSIn\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.2.min.js\": \"Ozhzj+SI7ywm74aOI/UajcWz+C0NjsPunEVyVIrxzYkB+jA+2tUw8x5xJCbVtK5I\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.2.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "stdout_hdlr = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('[%(asctime)s.%(msecs)03d - %(levelname)s] %(message)s')\n",
    "stdout_hdlr.setFormatter(formatter)\n",
    "_LOG.addHandler(stdout_hdlr)\n",
    "_LOG.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "If you are using a shapefile, csv file, or Amazon s3 link to the existing WIT run, \n",
    "the path must be set in the cell below this cell:\n",
    "\n",
    "* `shapefile`: NCI path to shapefile \n",
    "(e.g. `'/g/data1a/r78/DEA_Wetlands/shapefiles/ramsar_wetlands_3577_20190403.shp'`). \n",
    "You must have permissions to the project directory,\n",
    "and the shapefile must be in [Australian Albers EPSG 3577 projection](https://spatialreference.org/ref/epsg/gda94-australian-albers/)\n",
    "* `csv_file`: NCI path to WIT results CSV (e.g. `'/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'`)\n",
    "* `pd_yaml`: Yaml file necessary to generate WIT \n",
    "e.g. `'/g/data/u46/users/ea6141/wit_tooling/aux/fc_pd.yaml'`). \n",
    "Specifies input datasets.\n",
    "* `s3_url`: Amazon s3 url link to pre-generated WIT csvs folder \n",
    "(e.g. `'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/WIT_v3'`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put global variables in this cell\n",
    "\n",
    "shapefile = '/g/data1a/r78/DEA_Wetlands/shapefiles/ramsar_wetlands_3577_20190403.shp'\n",
    "csv_file = '/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'\n",
    "pd_yaml = '/g/data/u46/users/ea6141/wit_tooling/aux/fc_pd.yaml'\n",
    "s3_url = 'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/WIT_v3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used in this notebook to create, display and export Spatial WIT\n",
    "----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokeh_WIT_plot(WITdata, polyName='provided polygon'):\n",
    "    '''\n",
    "    last modified: May 2020\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    WITdata : xarray data array produced by load_wit_data function\n",
    "    polyName : string\n",
    "               A name for the polygon to identify the plot, optional. Defaults to 'provided polygon' \n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    A bokeh stack plot of the contents of the vector file in water, wet, green, dry and bare. Plot can be zoomed in to select a date. \n",
    "    '''\n",
    "    \n",
    "    #set up color palate for bokeh WIT plot\n",
    "    pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "           sns.xkcd_rgb[\"neon blue\"],\n",
    "           sns.xkcd_rgb[\"grass\"],\n",
    "           sns.xkcd_rgb[\"beige\"],\n",
    "           sns.xkcd_rgb[\"brown\"]]  \n",
    "\n",
    "    #these are tools we want to use in the plot\n",
    "    TOOLS = [\"pan, wheel_zoom, box_zoom, reset, tap, save\"]\n",
    "\n",
    "    #lets put a title on the plot\n",
    "    title =f'Percentage of area dominated by WOfS, Wetness, Fractional Cover for {polyName}'    \n",
    "\n",
    "    #set up the x axis to recognise date and time. Note that you will only see the days when you zoom in.\n",
    "    p =figure(plot_width=1200, \n",
    "              plot_height = 400, \n",
    "              x_axis_type='datetime',\n",
    "             title=title, tools=TOOLS)\n",
    "    p.sizing_mode = \"scale_width\"\n",
    "\n",
    "    #align the title in the centre\n",
    "    p.title.align= \"center\"\n",
    "    p.title.text_font_size=\"12pt\"\n",
    "\n",
    "    #label axes\n",
    "    p.yaxis.axis_label=(\"percentage of polygon classified as type\")\n",
    "    p.yaxis.axis_label_text_font_size=\"8pt\"\n",
    "\n",
    "    #we need screen units to put the attribution label under the plot. Don't ask why.\n",
    "    label_opts = dict(\n",
    "        x=0, \n",
    "        y=0,\n",
    "        x_units='screen', \n",
    "        y_units='screen',\n",
    "        text_font_style=\"italic\", \n",
    "        text_font_size=\"8.5pt\")\n",
    "    \n",
    "    #underplot context\n",
    "    msg1 = 'The Fractional Cover algorithm developed by the Joint Remote Sensing Research Program\\n\\\n",
    "    and the Water Observations from Space algorithm developed by Geoscience Australia are used in the production of this data'\n",
    "    caption1 = Label(text=msg1, **label_opts)\n",
    "\n",
    "    p.add_layout(caption1, 'below')\n",
    "\n",
    "    p.xaxis.formatter=DatetimeTickFormatter(years =[\"%Y\"], months=[\"%m/%Y\"] ,days=[\"%d/%m/%Y\"])\n",
    "    p.xaxis.major_label_orientation = 45\n",
    "\n",
    "    #create the actual stack plot using data from the pandas dataframe \n",
    "    p.varea_stack(['water', \n",
    "                  'wet',\n",
    "                  'green',\n",
    "                  'dry',\n",
    "                  'bare'], x= 'utc_time', color=pal, fill_alpha=0.7, source = WITdata, \n",
    "                  legend_label=[\"water\",\"wet\",\"green\",\"dry\",\"bare\"], muted_color=\"grey\", muted_alpha=0.2)\n",
    "\n",
    "\n",
    "    #set the new WIT graph ranges.\n",
    "    left, right, bottom, top = WITdata.index[0], WITdata.index[-1], 0, 100 #set \n",
    "    p.x_range=Range1d(left, right)\n",
    "    p.y_range=Range1d(bottom, top)\n",
    "    p.xaxis.bounds=(left,right)\n",
    "    p.yaxis.bounds=(bottom,top)\n",
    "\n",
    "    #now we want to overplot the data on the plot\n",
    "    #create rectangle borders for no-data times (SLC-off only)\n",
    "    LS5_8_gap_start = datetime(2011,11,1)\n",
    "    LS5_8_gap_end = datetime(2013,4,1)\n",
    "\n",
    "    #plot our dead satellite rectangle\n",
    "    p.hbar(y=50, \n",
    "           height=100,\n",
    "           left=LS5_8_gap_start, \n",
    "           right=LS5_8_gap_end, \n",
    "           color=\"white\", \n",
    "           alpha=0.5, \n",
    "           hatch_color=\"white\", \n",
    "           hatch_pattern='/',\n",
    "           hatch_alpha=0.6,\n",
    "           line_color=\"white\",\n",
    "           line_width =2,\n",
    "           line_alpha=0.6)\n",
    "\n",
    "    p.legend\n",
    "    p.legend.location=\"bottom_left\"\n",
    "    p.legend.click_policy=\"mute\"\n",
    "    p.legend.background_fill_alpha=0.5\n",
    "    p.legend.border_line_alpha=0.5\n",
    "    p.legend.label_text_font_size=\"9pt\" \n",
    "\n",
    "    #reverse the legend \n",
    "    p.legend[0].items.reverse()\n",
    "\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_WIT(spatial_wit_xr):\n",
    "    \"\"\"\n",
    "        plot spatial wit\n",
    "        input:\n",
    "            an xarray of spatial wit\n",
    "        output:\n",
    "            figure from bokeh\n",
    "    \"\"\"\n",
    "    image_list = [spatial_wit_xr[var].data[0] for var in spatial_wit_xr.data_vars]\n",
    "    # all below is to setup the pallete\n",
    "    transparent_white = RGB(255, 255, 255, 0)\n",
    "    colbat_blue = [RGB(3, 10, 167, 1)]\n",
    "    neon_blue = [RGB(4, 217, 255, 1)]\n",
    "    grass_green = [RGB(63, 155, 11, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "    soil_brown = [RGB(96, 70, 15, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "    dry_biege = [RGB(230, 218, 166, t) for t in np.arange(0.1, 1, 0.1) ]\n",
    "    var_colors = [soil_brown, grass_green, dry_biege, neon_blue, colbat_blue]\n",
    "    color_map = [LinearColorMapper([transparent_white]+c, low=0, high=100,\n",
    "                                   nan_color=transparent_white) for c in var_colors]\n",
    "    \n",
    "    # do the image plot\n",
    "    p =figure(plot_width=900, plot_height = 900,\n",
    "             tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")])\n",
    "\n",
    "    for i in range(5):\n",
    "        p.image(image=image_list[i:i+1], x=fc_wofs_data.x.data.min(), y=fc_wofs_data.y.data.max(),\n",
    "            dh=(fc_wofs_data.x.data.max() - fc_wofs_data.x.data.min()),\n",
    "            dw=(fc_wofs_data.y.data.max() - fc_wofs_data.y.data.min()),\n",
    "            color_mapper = color_map[i])\n",
    "    # to do\n",
    "    # legend, title, tooltip to show rignt value bla...\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geotiff(spatial_wit_xr, filename):\n",
    "    \"\"\"\n",
    "        save spatial WIT result to geotiffs, each band will be output to individual tiff\n",
    "        input:\n",
    "            an xarray Dataset of spatial WIT\n",
    "        output:\n",
    "            multiple cloud-optimized geotiffs (cogs) on disk\n",
    "    \"\"\"\n",
    "    for var in spatial_wit_xr.data_vars:\n",
    "        \n",
    "        #create file name per band\n",
    "        band_output = file_name + \"_\" + var + \".tif\"\n",
    "        #get spatial attributes from the parent dataset\n",
    "        geotiff_out_wit = spatial_wit_xr[var]\n",
    "        geotiff_out_wit.attrs = spatial_wit_xr.attrs\n",
    "        write_cog(geotiff_out_wit, band_output, blocksize=16)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(wit_df):\n",
    "    \"\"\"\n",
    "        Rename and reindex the input DataFrame\n",
    "        input: \n",
    "            loaded wit data as pandas DataFrame\n",
    "        output:\n",
    "            renamed and reindexed pandas DataFrame\n",
    "    \"\"\"\n",
    "    #give the index a name that reflects that it is time, measured in UTC not AEDT/AEST\n",
    "    wit_df = wit_df.set_index('TIME')\n",
    "    wit_df.index.name = 'utc_time'\n",
    "    #format the index of the dataframe as a date, not as a string\n",
    "    wit_df.index = pd.to_datetime(wit_df.index)\n",
    "    #Rename the columns so they are easier to understand and plot\n",
    "    wit_df = wit_df.rename(columns={\"WATER\" : \"water\", \n",
    "                            \"WET\" : \"wet\",\n",
    "                           \"PV\" : \"green\",\n",
    "                           \"NPV\" : \"dry\",\n",
    "                           \"BS\" : \"bare\"}) \n",
    "    #converting to percentages to make plotting easier\n",
    "    #first convert if not already a percentage\n",
    "    if wit_df.max().max() <=1.0:\n",
    "        wit_df = wit_df*100\n",
    "    #WITdata.head()\n",
    "    return wit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wit_data(**kwargs):\n",
    "    \"\"\"\n",
    "        Load pre-computed wit data from 3 different sources with the given parameter. Source is chosen by the key\n",
    "        in kwargs.\n",
    "        input:\n",
    "            csv = csv_path: csv file path\n",
    "            shape = a shape from shape file: a shape from shape file\n",
    "            s3_url = ulr of s3 bucket: s3 bucket path\n",
    "        output:\n",
    "            panda dataframe of wit data\n",
    "    \"\"\"\n",
    "    if kwargs.get(\"csv\") is not None:\n",
    "        wit_data = pd.read_csv(kwargs['csv'])\n",
    "    elif kwargs.get('shape') is not None:\n",
    "        _, wit_data = query_wit_data(kwargs['shape'])\n",
    "        wit_data = pd.DataFrame(data=wit_data, columns=['TIME', 'BS', 'NPV', 'PV', 'WET', 'WATER'])\n",
    "    elif kwargs.get('s3_url') is not None:\n",
    "        wit_data = pd.read_csv(kwargs['s3_url'], infer_datetime_format=True)\n",
    "    return wit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next three functions are used to load fc and wofs data with give geometry and time\n",
    "def construct_product(product_yaml):\n",
    "    \"\"\"\n",
    "        Construct a virtual product with the given yaml file\n",
    "        input:\n",
    "            product_yaml: the yaml file path\n",
    "        output:\n",
    "            virtual product instance\n",
    "    \"\"\"\n",
    "    with open(product_yaml, 'r') as f:\n",
    "        recipe = yaml.safe_load(f)\n",
    "    fc_product = construct(**recipe)\n",
    "    return fc_product\n",
    "\n",
    "def query_datasets(fc_product, shape, crs, time_range):\n",
    "    \"\"\"\n",
    "        Query the datasets in datacube database with the given shape and time period\n",
    "        input:\n",
    "            fc_product: virtual product instance\n",
    "            shape: a shape from shape file\n",
    "            crs: crs string from shape file\n",
    "            time_range: a tuple of (start_time, end_time)\n",
    "        output:\n",
    "            grouped datasets: VirtualDatasetBox\n",
    "    \"\"\"\n",
    "    dc = Datacube()\n",
    "    query_poly = convert_shape_to_polygon(shape['geometry'])\n",
    "    query_poly = Geometry(mapping(box(*query_poly.bounds)), CRS(crs))\n",
    "    query = {'geopolygon': query_poly, 'time': time_range}\n",
    "    datasets = fc_product.query(dc, **query)\n",
    "    grouped = fc_product.group(datasets, **query)\n",
    "    return grouped\n",
    "\n",
    "def load_wofs_fc(fc_product, grouped, time_slice):\n",
    "    \"\"\"\n",
    "        Load cloud free wofs, TCW and FC data with the given time or a tuple of (start_time, end_time)\n",
    "        input:\n",
    "            fc_product: virtual product instance\n",
    "            grouped: grouped datasets\n",
    "            time_slice: a single time or tuple of (start_time, end_time)\n",
    "        output:\n",
    "            wofs, TCW and FC data: xr.Dataset\n",
    "    \"\"\"\n",
    "    if not (isinstance(time_slice, list) or isinstance(time_slice, tuple)):\n",
    "         time_slice = [time_slice]\n",
    "    to_load = VirtualDatasetBox(grouped.box.loc[time_slice], grouped.geobox,\n",
    "                grouped.load_natively, grouped.product_definitions, grouped.geopolygon)\n",
    "    fc_wofs_data = load_timeslice(fc_product, to_load)\n",
    "    return fc_wofs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_wit(fc_wofs_data, mask):\n",
    "    \"\"\"\n",
    "        Compute spatial wit with wofs, TCW and FC data with the given polygon mask\n",
    "        input:\n",
    "            fc_wofs_data: wofs, TCW and FC data: xr.Dataset\n",
    "            mask: a polygon mask: np.array\n",
    "        output:\n",
    "            spatial wit results: xr.Dataset\n",
    "    \"\"\"\n",
    "    none_water_vars = list(fc_wofs_data.data_vars)[:-1]\n",
    "    water_var = list(fc_wofs_data.data_vars)[-1]\n",
    "    fc_data = fc_wofs_data[none_water_vars].where(fc_wofs_data[water_var] < 1, 0)\n",
    "    tcw_percent = fc_data['TCW'] >= -350\n",
    "    fc_percent = fc_data.drop('TCW').where(~tcw_percent, 0)\n",
    "    fc_wofs_perc = xr.merge([fc_percent, (tcw_percent.astype(\"int\") * 100),\n",
    "                             (fc_wofs_data[water_var].astype(\"int\") * 100)])\n",
    "    fc_wofs_perc = fc_wofs_perc.where(mask == int(shape['id']), -127).astype(\"int16\")\n",
    "    fc_wofs_perc.attrs.update(fc_wofs_data.attrs)\n",
    "    for var in fc_wofs_perc.data_vars:\n",
    "        fc_wofs_perc[var].attrs['nodata'] = -127\n",
    "    return fc_wofs_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main : \n",
    "here we run functions and produce outputs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded shape id 0, Myall Lakes, Corrie Island Nature Reserve\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bare</th>\n",
       "      <th>dry</th>\n",
       "      <th>green</th>\n",
       "      <th>wet</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utc_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1987-05-22 23:07:43.500</th>\n",
       "      <td>3.01791</td>\n",
       "      <td>7.79725</td>\n",
       "      <td>14.3224</td>\n",
       "      <td>64.023</td>\n",
       "      <td>10.5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987-09-11 23:10:29.500</th>\n",
       "      <td>4.10354</td>\n",
       "      <td>10.0363</td>\n",
       "      <td>16.2926</td>\n",
       "      <td>55.1768</td>\n",
       "      <td>14.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987-10-29 23:11:25.000</th>\n",
       "      <td>4.27089</td>\n",
       "      <td>11.4134</td>\n",
       "      <td>20.8895</td>\n",
       "      <td>54.5629</td>\n",
       "      <td>8.42139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-17 23:12:49.500</th>\n",
       "      <td>0.952721</td>\n",
       "      <td>3.0068</td>\n",
       "      <td>6.57585</td>\n",
       "      <td>58.0272</td>\n",
       "      <td>31.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-02-18 23:13:23.000</th>\n",
       "      <td>2.24369</td>\n",
       "      <td>4.65846</td>\n",
       "      <td>10.6758</td>\n",
       "      <td>68.2449</td>\n",
       "      <td>13.9836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bare      dry    green      wet    water\n",
       "utc_time                                                             \n",
       "1987-05-22 23:07:43.500   3.01791  7.79725  14.3224   64.023  10.5532\n",
       "1987-09-11 23:10:29.500   4.10354  10.0363  16.2926  55.1768  14.0152\n",
       "1987-10-29 23:11:25.000   4.27089  11.4134  20.8895  54.5629  8.42139\n",
       "1988-01-17 23:12:49.500  0.952721   3.0068  6.57585  58.0272  31.3265\n",
       "1988-02-18 23:13:23.000   2.24369  4.65846  10.6758  68.2449  13.9836"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wit data from database with a chosen shape\n",
    "with fiona.open(shapefile) as allshapes:\n",
    "    shape_crs = allshapes.crs_wkt\n",
    "    shape = next(iter(allshapes))\n",
    "    wit_data = load_wit_data(shape=shape)\n",
    "\n",
    "# or load from s3 bucket\n",
    "# s3_filename = 'Kerang%20Wetlands_Hird%20Swamp_VIC_17.csv'\n",
    "# wit_data = load_wit_data(s3_url='/'.join([s3_url, s3_filename]))\n",
    "\n",
    "# or load from local csv\n",
    "# wit_data = load_wit_data(csv=csv_file)\n",
    "\n",
    "wit_data = rename_columns(wit_data)\n",
    "\n",
    "#print some details about the shapefile. \n",
    "#You will have to change this for other shapefiles\n",
    "print(f\"loaded shape id {shape['id']},\\\n",
    " {shape['properties']['RAMSAR_NAM']}, {shape['properties']['WETLAND_NA']}\")\n",
    "wit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack plot of wit\n",
    "plot = bokeh_WIT_plot(wit_data, polyName)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a(more) time slice(s)\n",
    "# it's helpful to get the location of data rather than load them\n",
    "# and it will save you time without querying database multiple times\n",
    "time_range = (wit_data.index.min(), wit_data.index.max())\n",
    "fc_product = construct_product(pd_yaml)\n",
    "datasets = query_datasets(fc_product, shape, shape_crs, time_range)\n",
    "_LOG.debug(\"Query datasets %s\", datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then decide with slice(s) you want to load\n",
    "# e.g. 1988-02-18 23:13:23.000  in wit_data concers you\n",
    "time_slice = np.datetime64(wit_data.index[4])\n",
    "_LOG.debug(\"load time slice %s\", time_slice)\n",
    "fc_wofs_data = load_wofs_fc(fc_product, datasets, time_slice)\n",
    "# mask by the geometry of given polygon\n",
    "# first parameter of generate_raster is a tuple of (gemoetry, a_int)\n",
    "mask = generate_raster([(shape['geometry'], int(shape['id']))], datasets.geobox)\n",
    "fc_wofs_perc = spatial_wit(fc_wofs_data, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spatial WIT\n",
    "plot = plot_spatial_WIT(fc_wofs_perc)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_wit_xr = fc_wofs_perc\n",
    "image_list = [spatial_wit_xr[var].data[0] for var in spatial_wit_xr.data_vars]\n",
    "# all below is to setup the pallete\n",
    "transparent_white = RGB(255, 255, 255, 0)\n",
    "colbat_blue = [RGB(3, 10, 167, 1)]\n",
    "neon_blue = [RGB(4, 217, 255, 1)]\n",
    "grass_green = [RGB(63, 155, 11, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "soil_brown = [RGB(96, 70, 15, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "dry_biege = [RGB(230, 218, 166, t) for t in np.arange(0.1, 1, 0.1) ]\n",
    "var_colors = [soil_brown, grass_green, dry_biege, neon_blue, colbat_blue]\n",
    "color_map = [LinearColorMapper([transparent_white]+c, low=0, high=100,\n",
    "                               nan_color=transparent_white) for c in var_colors]\n",
    "\n",
    "# do the image plot\n",
    "p =figure(plot_width=900, plot_height = 900,\n",
    "         tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")])\n",
    "\n",
    "for i in range(5):\n",
    "    p.image(image=image_list[i:i+1], x=fc_wofs_data.x.data.min(), y=fc_wofs_data.y.data.max(),\n",
    "        dh=(fc_wofs_data.x.data.max() - fc_wofs_data.x.data.min()),\n",
    "        dw=(fc_wofs_data.y.data.max() - fc_wofs_data.y.data.min()),\n",
    "        color_mapper = color_map[i])\n",
    "# to do\n",
    "# legend, title, tooltip to show rignt value bla...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the nan functionality\n",
    "nand = fc_wofs_perc.where(fc_wofs_perc>=0)\n",
    "nand.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spatial WIT as geotiff\n",
    "# each variable will be output to individual COG\n",
    "# file_name works as prefix, the final output file name will be \"file_name_bandname\", e.g. \"test_BS.tif\"\n",
    "file_name = \"test2\"\n",
    "\n",
    "save_geotiff(fc_wofs_perc, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
