{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidal regression\n",
    "\n",
    "**What does this notebook do?** \n",
    "\n",
    "This notebook uses the ([OSU Tidal Prediction Software or OTPS](http://volkov.oce.orst.edu/tides/otps.html)) to tidally tag a time series of Landsat imagery, and then compute pixel-wise regression based on NDWI values.\n",
    "\n",
    "**Requirements:** \n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "`module load otps`\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date:** August 2018\n",
    "\n",
    "**Authors:** Robbi Bishop-Taylor, Bex Dunn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`tidal_model`, :index:`OTPS`, :index:`tidal_tagging`, :index:`predict_tide`, :index:`composites`, :index:`datacube.utils.geometry`, :index:`dask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T04:55:25.713266Z",
     "start_time": "2018-09-03T04:55:24.421634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from otps import TimePoint\n",
    "from otps import predict_tide\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "\n",
    "# Import external functions from dea-notebooks using relative link to Scripts\n",
    "sys.path.append('../10_Scripts')\n",
    "import DEAPlotting\n",
    "import DEADataHandling\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Create datacube instance\n",
    "dc = datacube.Datacube(app='Tidal regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import remotely-sensed time series data\n",
    "Imports a time series of Landsat observations as a DEA `xarray` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-03T04:55:25.817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ls5 PQ\n"
     ]
    }
   ],
   "source": [
    "# Set up analysis data query using \n",
    "lat, lon, buffer = -12.463, 130.885, 3500\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),         \n",
    "         'crs': 'EPSG:3577',\n",
    "         'time': ('1987-01-01', '2018-06-30')}\n",
    "\n",
    "# Mask used to identify bad pixels\n",
    "mask_dict = {'cloud_acca': 'no_cloud', \n",
    "             'cloud_fmask': 'no_cloud', \n",
    "             'cloud_shadow_acca':'no_cloud_shadow',\n",
    "             'cloud_shadow_fmask':'no_cloud_shadow',\n",
    "             'blue_saturated':False,\n",
    "             'green_saturated':False,\n",
    "             'red_saturated':False,\n",
    "             'nir_saturated':False,\n",
    "             'swir1_saturated':False,\n",
    "             'swir2_saturated':False,\n",
    "             'contiguous': True}\n",
    "\n",
    "# Import data\n",
    "data = DEADataHandling.load_clearlandsat(dc=dc, query=query, sensors=['ls5', 'ls7', 'ls8'],\n",
    "                                         bands_of_interest=['swir1', 'nir', 'green'],\n",
    "                                         mask_dict=mask_dict, masked_prop=0.8, apply_mask=True)\n",
    "\n",
    "# Plot data\n",
    "data[['swir1', 'nir', 'green']].isel(time=6).to_array().plot.imshow(robust=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidal modelling using OTPS\n",
    "and extracts a list of timestamps based on the time and date of acquisition for each Landsat observation. These timestamps can then be used as one of the inputs to the [OSU Tidal Prediction Software (OTPS) tidal model](http://volkov.oce.orst.edu/tides/otps.html) to compute tidal heights at the time of acquisition of each Landsat observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-03T04:55:27.535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract list of datetimes based on Landsat time of acquisition for each image\n",
    "observed_datetimes = data.time.data.astype('M8[s]').astype('O').tolist()\n",
    "\n",
    "#Set a tide post: this is the location the OTPS model uses to compute tides for the supplied datetimes\n",
    "tidepost_lat, tidepost_lon = -12.48315, 130.85540\n",
    "\n",
    "# The OTPS model requires inputs as 'TimePoint' objects, which are combinations of lon-lat coordinates \n",
    "# and a datetime object. You can create a list of these with a list comprehension:\n",
    "observed_timepoints = [TimePoint(tidepost_lon, tidepost_lat, dt) for dt in observed_datetimes]\n",
    "\n",
    "# Feed the entire list of timepoints to the OTPS `predict_tide` function:\n",
    "observed_predictedtides = predict_tide(observed_timepoints)\n",
    "\n",
    "# For each of the predicted tide objects, extract a list of tidal heights in `m` units relative to mean \n",
    "# sea level (the `tide_m` method should not be confused with the `depth_m` method, which gives you the \n",
    "# ocean depth at the tide post location that is used by the OTPS model to predict tides)\n",
    "observed_tideheights = [predictedtide.tide_m for predictedtide in observed_predictedtides]\n",
    "\n",
    "# Create a dataframe of tidal heights for each Landsat observation\n",
    "observed_df = pd.DataFrame({'tide_height': observed_tideheights}, \n",
    "                           index=pd.DatetimeIndex(observed_datetimes))\n",
    "\n",
    "# Plot tidal heights against Landsat observation date\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.scatter(observed_df.index, observed_df.tide_height, linewidth=0.6, zorder=1, label='Modelled')\n",
    "ax.set_title('Landsat observations by tidal height (m)')\n",
    "ax.set_ylabel('Tide height (m)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging, filtering and compositing Landsat observations by tidal height/stage\n",
    "Adds tidal height data back into our original `xarray` dataset so that each Landsat observation is correctly tagged with its corresponding tidal height. Tagged images can then be filtered or composited to study characteristics of the coastline at various tidal stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MNDWI for all timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.587552Z",
     "start_time": "2018-09-02T23:20:37.927Z"
    }
   },
   "outputs": [],
   "source": [
    "data['mndwi'] = (data.green - data.swir1) / (data.green + data.swir1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.590231Z",
     "start_time": "2018-09-02T23:20:38.146Z"
    }
   },
   "outputs": [],
   "source": [
    "data['mndwi'].plot(col='time', col_wrap=6, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T01:29:39.592597Z",
     "start_time": "2018-08-31T01:29:25.064Z"
    }
   },
   "source": [
    "### Set up linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T05:11:01.165055Z",
     "start_time": "2018-09-03T05:11:00.913926Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed2db55da8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "len(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T05:11:01.708758Z",
     "start_time": "2018-09-03T05:11:01.692149Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a01fd1345ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "ones =np.ones((len(data.x), len(data.y)), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.595034Z",
     "start_time": "2018-09-02T23:20:39.678Z"
    }
   },
   "outputs": [],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.596557Z",
     "start_time": "2018-09-02T23:20:39.968Z"
    }
   },
   "outputs": [],
   "source": [
    "data.tide_heights=data.tide_heights*ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.598155Z",
     "start_time": "2018-09-02T23:20:40.284Z"
    }
   },
   "outputs": [],
   "source": [
    "data.mndwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.599591Z",
     "start_time": "2018-09-02T23:20:40.951Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(data.mndwi, data.tide_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.601107Z",
     "start_time": "2018-09-02T23:20:41.256Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.602593Z",
     "start_time": "2018-09-02T23:20:41.516Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_trend(ds):\n",
    "    pf = np.polyfit(ds.tide_heights, ds, 1)\n",
    "    # we need to return a dataarray or else xarray's groupby won't be happy\n",
    "    return xr.DataArray(pf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.604055Z",
     "start_time": "2018-09-02T23:20:41.779Z"
    }
   },
   "outputs": [],
   "source": [
    "data=data.drop(['data_perc','swir1','nir','green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.605484Z",
     "start_time": "2018-09-02T23:20:42.034Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked = data.stack(space=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.606881Z",
     "start_time": "2018-09-02T23:20:42.334Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.608307Z",
     "start_time": "2018-09-02T23:20:42.633Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.609704Z",
     "start_time": "2018-09-02T23:20:42.992Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked.groupby('space').apply(stats.linregress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.611149Z",
     "start_time": "2018-09-02T23:20:44.339Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked.tide_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.612532Z",
     "start_time": "2018-09-02T23:20:44.636Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked.mndwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.613939Z",
     "start_time": "2018-09-02T23:20:44.934Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.linregress(stacked.tide_heights,stacked.mndwi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T06:29:12.743320Z",
     "start_time": "2018-08-31T06:29:11.406054Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.615330Z",
     "start_time": "2018-09-02T23:20:45.452Z"
    }
   },
   "outputs": [],
   "source": [
    "data.tide_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.616685Z",
     "start_time": "2018-09-02T23:20:45.675Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_sorted.tide_heights, data_sorted.mndwi.mean(dim=['x','y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.618174Z",
     "start_time": "2018-09-02T23:20:45.918Z"
    }
   },
   "outputs": [],
   "source": [
    "data_mask=np.isfinite(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T07:28:49.963411Z",
     "start_time": "2018-08-31T07:28:48.710053Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.619475Z",
     "start_time": "2018-09-02T23:20:46.395Z"
    }
   },
   "outputs": [],
   "source": [
    "data['tide_heights2']=data['mndwi']*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.620964Z",
     "start_time": "2018-09-02T23:20:46.631Z"
    }
   },
   "outputs": [],
   "source": [
    "data_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.622383Z",
     "start_time": "2018-09-02T23:20:47.885Z"
    }
   },
   "outputs": [],
   "source": [
    "#This function applies a linear regression to a grid over a set time interval\n",
    "def linear_regression_grid(input_array, mask_no_trend = False):\n",
    "    '''\n",
    "    This function applies a linear regression to a grid over a set time interval by looping through lat and lon \n",
    "    and calculating the linear regression through time for each pixel.\n",
    "    '''\n",
    "    print(input_array.tide_heights)\n",
    "    ylen = len(input_array.y)\n",
    "    xlen = len(input_array.x)\n",
    "    from itertools import product\n",
    "    coordinates = product(range(ylen), range(xlen))\n",
    "\n",
    "    slopes = np.zeros((ylen, xlen))\n",
    "    p_values = np.zeros((ylen, xlen))\n",
    "    #print('Slope shape is ', slopes.shape)\n",
    "\n",
    "    for y, x in coordinates:\n",
    "        val = input_array.isel(x = x, y = y)\n",
    "        print (val.tide_heights, val.mndwi)\n",
    "        #slopes[y, x], intercept, r_sq, p_values[y, x], std_err = stats.linregress(val.tide_heights,val.mndwi)\n",
    "\n",
    "#     #Get coordinates from the original xarray\n",
    "#     lat  = input_array.coords['y']\n",
    "#     long = input_array.coords['x']\n",
    "#     #Mask out values with insignificant trends (ie. p-value > 0.05) if user wants\n",
    "#     if mask_no_trend == True:\n",
    "#         slopes[p_values>0.05]=np.nan        \n",
    "#     # Write arrays into a x-array\n",
    "#     slope_xr = xr.DataArray(slopes, coords = [lat, long], dims = ['y', 'x'])\n",
    "#     p_val_xr = xr.DataArray(p_values, coords = [lat, long], dims = ['y', 'x']) \n",
    "#     return slope_xr, p_val_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.623706Z",
     "start_time": "2018-09-02T23:20:48.861Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_regression_grid(data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.625140Z",
     "start_time": "2018-09-02T23:20:48.966Z"
    }
   },
   "outputs": [],
   "source": [
    "data_sorted = data.sortby(data.tide_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.626468Z",
     "start_time": "2018-09-02T23:20:49.036Z"
    }
   },
   "outputs": [],
   "source": [
    "slope_xr, intercept, r_sq, p_val_xr, std_err = linear_regression_grid(data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.627839Z",
     "start_time": "2018-09-02T23:20:49.102Z"
    }
   },
   "outputs": [],
   "source": [
    "slope_xr, p_val_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.629150Z",
     "start_time": "2018-09-02T23:20:49.392Z"
    }
   },
   "outputs": [],
   "source": [
    "p_val_xr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T23:20:54.630545Z",
     "start_time": "2018-09-02T23:20:49.673Z"
    }
   },
   "outputs": [],
   "source": [
    "# #This function applies a linear regression to a grid over a set time interval\n",
    "# def linear_regression_grid(input_array, mask_no_trend = False, NDVI = False):\n",
    "#     '''\n",
    "#     This function applies a linear regression to a grid over a set time interval by looping through lat and lon \n",
    "#     and calculating the linear regression through time for each pixel.\n",
    "#     '''\n",
    "#     print(input_array.year)\n",
    "#     ylen = len(input_array.y)\n",
    "#     xlen = len(input_array.x)\n",
    "#     from itertools import product\n",
    "#     coordinates = product(range(ylen), range(xlen))\n",
    "\n",
    "#     slopes = np.zeros((ylen, xlen))\n",
    "#     p_values = np.zeros((ylen, xlen))\n",
    "#     print('Slope shape is ', slopes.shape)\n",
    "\n",
    "#     for y, x in coordinates:\n",
    "#         val = input_array.isel(x = x, y = y)\n",
    "#         # If analysing NDVI data replace negative numbers which are spurious for NDVI with nans\n",
    "#         if NDVI == True:\n",
    "#             val[val<0] = np.nan\n",
    "\n",
    "#             # Check that we have at least three values to perform our linear regression on\n",
    "#             if np.count_nonzero(~np.isnan(val)) > 3:\n",
    "#                 if str(val.dims[0]) == 'month':\n",
    "#                     slopes[y, x], intercept, r_sq, p_values[y, x], std_err = stats.linregress(val.month,val)\n",
    "#                 elif str(val.dims[0]) == 'year':\n",
    "#                     slopes[y, x], intercept, r_sq, p_values[y, x], std_err = stats.linregress(val.year,val)\n",
    "#             else:\n",
    "#                 slopes[y, x] = np.nan\n",
    "#                 intercept = np.nan\n",
    "#                 r_sq = np.nan\n",
    "#                 p_values[y, x] = np.nan\n",
    "#         else:\n",
    "#             if str(val.dims[0]) == 'month':\n",
    "#                 slopes[y, x], intercept, r_sq, p_values[y, x], std_err = stats.linregress(val.month,val)\n",
    "#             elif str(val.dims[0]) == 'year':\n",
    "#                 slopes[y, x], intercept, r_sq, p_values[y, x], std_err = stats.linregress(val.year,val)\n",
    "\n",
    "#     #Get coordinates from the original xarray\n",
    "#     lat  = input_array.coords['y']\n",
    "#     long = input_array.coords['x']\n",
    "#     #Mask out values with insignificant trends (ie. p-value > 0.05) if user wants\n",
    "#     if mask_no_trend == True:\n",
    "#         slopes[p_values>0.05]=np.nan        \n",
    "#     # Write arrays into a x-array\n",
    "#     slope_xr = xr.DataArray(slopes, coords = [lat, long], dims = ['y', 'x'])\n",
    "#     p_val_xr = xr.DataArray(p_values, coords = [lat, long], dims = ['y', 'x']) \n",
    "#     return slope_xr, p_val_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
